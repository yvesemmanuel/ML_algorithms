{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlp_ensemble import MlpEnsemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Getting training && validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../databases/training.csv')\n",
    "X_train, y_train = df_train.drop(['IND_BOM_1_1'], axis=1), df_train['IND_BOM_1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('../databases/validation.csv')\n",
    "X_val, y_val = df_valid.drop(['IND_BOM_1_1'], axis=1), df_valid['IND_BOM_1_1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MLP Ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = [\n",
    "    {\n",
    "        'hidden_layer_units': 256,\n",
    "        'activation': 'sigmoid',\n",
    "        'hidden_layers': 1,\n",
    "        'dropout_rate': 0.5,\n",
    "        'output_activation': 'sigmoid',\n",
    "        'alpha': 0.01,\n",
    "        'optimizer': 'Adam',\n",
    "        'loss_function': 'mse',\n",
    "        'batch_size': 32,\n",
    "        'max_iter': 2000\n",
    "    },\n",
    "    {\n",
    "        'hidden_layer_units': 256,\n",
    "        'activation': 'sigmoid',\n",
    "        'hidden_layers': 1,\n",
    "        'dropout_rate': 0.5,\n",
    "        'output_activation': 'sigmoid',\n",
    "        'alpha': 0.001,\n",
    "        'optimizer': 'Adam',\n",
    "        'loss_function': 'mse',\n",
    "        'batch_size': 32,\n",
    "        'max_iter': 5000\n",
    "    },\n",
    "    {\n",
    "        'hidden_layer_units': 256,\n",
    "        'activation': 'sigmoid',\n",
    "        'hidden_layers': 1,\n",
    "        'dropout_rate': 0.5,\n",
    "        'output_activation': 'sigmoid',\n",
    "        'alpha': 0.01,\n",
    "        'optimizer': 'Adam',\n",
    "        'loss_function': 'mse',\n",
    "        'batch_size': 128,\n",
    "        'max_iter': 2000\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = X_train.shape[1]\n",
    "ensemble_model = MlpEnsemble(models_params, input_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2351 - accuracy: 0.6075 - val_loss: 0.2431 - val_accuracy: 0.5922\n",
      "Epoch 2/2000\n",
      "5616/5616 [==============================] - 24s 4ms/step - loss: 0.2339 - accuracy: 0.6091 - val_loss: 0.2186 - val_accuracy: 0.6411\n",
      "Epoch 3/2000\n",
      "5616/5616 [==============================] - 24s 4ms/step - loss: 0.2321 - accuracy: 0.6137 - val_loss: 0.2540 - val_accuracy: 0.5491\n",
      "Epoch 4/2000\n",
      "5616/5616 [==============================] - 24s 4ms/step - loss: 0.2315 - accuracy: 0.6145 - val_loss: 0.2294 - val_accuracy: 0.5900\n",
      "Epoch 5/2000\n",
      "5616/5616 [==============================] - 24s 4ms/step - loss: 0.2314 - accuracy: 0.6160 - val_loss: 0.2138 - val_accuracy: 0.6620\n",
      "Epoch 6/2000\n",
      "5616/5616 [==============================] - 24s 4ms/step - loss: 0.2309 - accuracy: 0.6175 - val_loss: 0.2368 - val_accuracy: 0.6005\n",
      "Epoch 7/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2302 - accuracy: 0.6201 - val_loss: 0.2448 - val_accuracy: 0.5445\n",
      "Epoch 8/2000\n",
      "5616/5616 [==============================] - 24s 4ms/step - loss: 0.2301 - accuracy: 0.6194 - val_loss: 0.2197 - val_accuracy: 0.6143\n",
      "Epoch 9/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2302 - accuracy: 0.6179 - val_loss: 0.2292 - val_accuracy: 0.5680\n",
      "Epoch 10/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2301 - accuracy: 0.6189 - val_loss: 0.2267 - val_accuracy: 0.6022\n",
      "Epoch 11/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2298 - accuracy: 0.6199 - val_loss: 0.2403 - val_accuracy: 0.5926\n",
      "Epoch 12/2000\n",
      "5616/5616 [==============================] - 24s 4ms/step - loss: 0.2296 - accuracy: 0.6204 - val_loss: 0.2170 - val_accuracy: 0.6416\n",
      "Epoch 13/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2294 - accuracy: 0.6221 - val_loss: 0.2234 - val_accuracy: 0.6026\n",
      "Epoch 14/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2299 - accuracy: 0.6202 - val_loss: 0.2343 - val_accuracy: 0.5711\n",
      "Epoch 15/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2299 - accuracy: 0.6193 - val_loss: 0.2303 - val_accuracy: 0.6077\n",
      "Epoch 16/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2300 - accuracy: 0.6203 - val_loss: 0.2155 - val_accuracy: 0.6479\n",
      "Epoch 17/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2294 - accuracy: 0.6223 - val_loss: 0.2131 - val_accuracy: 0.6440\n",
      "Epoch 18/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2297 - accuracy: 0.6197 - val_loss: 0.2418 - val_accuracy: 0.5647\n",
      "Epoch 19/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2296 - accuracy: 0.6221 - val_loss: 0.2190 - val_accuracy: 0.6329\n",
      "Epoch 20/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2300 - accuracy: 0.6190 - val_loss: 0.2298 - val_accuracy: 0.6042\n",
      "Epoch 21/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2297 - accuracy: 0.6214 - val_loss: 0.2207 - val_accuracy: 0.6100\n",
      "Epoch 22/2000\n",
      "5616/5616 [==============================] - 24s 4ms/step - loss: 0.2294 - accuracy: 0.6204 - val_loss: 0.2391 - val_accuracy: 0.5652\n",
      "Epoch 23/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2292 - accuracy: 0.6220 - val_loss: 0.2230 - val_accuracy: 0.6217\n",
      "Epoch 24/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2289 - accuracy: 0.6231 - val_loss: 0.2282 - val_accuracy: 0.6009\n",
      "Epoch 25/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2300 - accuracy: 0.6186 - val_loss: 0.2298 - val_accuracy: 0.5935\n",
      "Epoch 26/2000\n",
      "5616/5616 [==============================] - 25s 5ms/step - loss: 0.2291 - accuracy: 0.6224 - val_loss: 0.2281 - val_accuracy: 0.5945\n",
      "Epoch 27/2000\n",
      "5616/5616 [==============================] - 25s 5ms/step - loss: 0.2294 - accuracy: 0.6237 - val_loss: 0.2133 - val_accuracy: 0.6647\n",
      "Epoch 28/2000\n",
      "5616/5616 [==============================] - 25s 5ms/step - loss: 0.2294 - accuracy: 0.6193 - val_loss: 0.2295 - val_accuracy: 0.6099\n",
      "Epoch 29/2000\n",
      "5616/5616 [==============================] - 25s 5ms/step - loss: 0.2290 - accuracy: 0.6244 - val_loss: 0.2077 - val_accuracy: 0.6744\n",
      "Epoch 30/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2292 - accuracy: 0.6203 - val_loss: 0.2146 - val_accuracy: 0.6512\n",
      "Epoch 31/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2295 - accuracy: 0.6207 - val_loss: 0.2365 - val_accuracy: 0.5930\n",
      "Epoch 32/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2298 - accuracy: 0.6220 - val_loss: 0.2346 - val_accuracy: 0.5728\n",
      "Epoch 33/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2300 - accuracy: 0.6197 - val_loss: 0.2380 - val_accuracy: 0.5568\n",
      "Epoch 34/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2304 - accuracy: 0.6190 - val_loss: 0.2161 - val_accuracy: 0.6396\n",
      "Epoch 35/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2299 - accuracy: 0.6198 - val_loss: 0.2147 - val_accuracy: 0.6494\n",
      "Epoch 36/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2298 - accuracy: 0.6221 - val_loss: 0.2287 - val_accuracy: 0.6009\n",
      "Epoch 37/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2294 - accuracy: 0.6232 - val_loss: 0.2312 - val_accuracy: 0.5763\n",
      "Epoch 38/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2298 - accuracy: 0.6214 - val_loss: 0.2148 - val_accuracy: 0.6563\n",
      "Epoch 39/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2295 - accuracy: 0.6232 - val_loss: 0.2213 - val_accuracy: 0.6221\n",
      "Epoch 40/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2289 - accuracy: 0.6226 - val_loss: 0.2220 - val_accuracy: 0.6165\n",
      "Epoch 41/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2294 - accuracy: 0.6205 - val_loss: 0.2212 - val_accuracy: 0.6052\n",
      "Epoch 42/2000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2292 - accuracy: 0.6211 - val_loss: 0.2343 - val_accuracy: 0.5540\n",
      "Epoch 43/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2296 - accuracy: 0.6221 - val_loss: 0.2305 - val_accuracy: 0.5739\n",
      "Epoch 44/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2293 - accuracy: 0.6214 - val_loss: 0.2370 - val_accuracy: 0.5695\n",
      "Epoch 45/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2292 - accuracy: 0.6210 - val_loss: 0.2195 - val_accuracy: 0.6053\n",
      "Epoch 46/2000\n",
      "5616/5616 [==============================] - 25s 5ms/step - loss: 0.2295 - accuracy: 0.6217 - val_loss: 0.2364 - val_accuracy: 0.5866\n",
      "Epoch 47/2000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2296 - accuracy: 0.6218 - val_loss: 0.2417 - val_accuracy: 0.5656\n",
      "Epoch 48/2000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2295 - accuracy: 0.6228 - val_loss: 0.2093 - val_accuracy: 0.6732\n",
      "Epoch 49/2000\n",
      "5609/5616 [============================>.] - ETA: 0s - loss: 0.2290 - accuracy: 0.6243Restoring model weights from the end of the best epoch: 29.\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2290 - accuracy: 0.6243 - val_loss: 0.2198 - val_accuracy: 0.6474\n",
      "Epoch 49: early stopping\n",
      "Epoch 1/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2321 - accuracy: 0.6117 - val_loss: 0.2216 - val_accuracy: 0.6321\n",
      "Epoch 2/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2259 - accuracy: 0.6302 - val_loss: 0.2265 - val_accuracy: 0.6206\n",
      "Epoch 3/5000\n",
      "5616/5616 [==============================] - 25s 4ms/step - loss: 0.2238 - accuracy: 0.6335 - val_loss: 0.2114 - val_accuracy: 0.6562\n",
      "Epoch 4/5000\n",
      "5616/5616 [==============================] - 25s 5ms/step - loss: 0.2224 - accuracy: 0.6370 - val_loss: 0.2256 - val_accuracy: 0.6173\n",
      "Epoch 5/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2214 - accuracy: 0.6397 - val_loss: 0.2271 - val_accuracy: 0.6154\n",
      "Epoch 6/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2202 - accuracy: 0.6419 - val_loss: 0.2175 - val_accuracy: 0.6373\n",
      "Epoch 7/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2194 - accuracy: 0.6437 - val_loss: 0.2245 - val_accuracy: 0.6270\n",
      "Epoch 8/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2184 - accuracy: 0.6455 - val_loss: 0.2212 - val_accuracy: 0.6326\n",
      "Epoch 9/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2173 - accuracy: 0.6484 - val_loss: 0.2194 - val_accuracy: 0.6397\n",
      "Epoch 10/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2162 - accuracy: 0.6515 - val_loss: 0.2325 - val_accuracy: 0.6107\n",
      "Epoch 11/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2150 - accuracy: 0.6538 - val_loss: 0.2227 - val_accuracy: 0.6317\n",
      "Epoch 12/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2137 - accuracy: 0.6564 - val_loss: 0.2262 - val_accuracy: 0.6212\n",
      "Epoch 13/5000\n",
      "5616/5616 [==============================] - 26s 5ms/step - loss: 0.2125 - accuracy: 0.6585 - val_loss: 0.2210 - val_accuracy: 0.6372\n",
      "Epoch 14/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2111 - accuracy: 0.6615 - val_loss: 0.2257 - val_accuracy: 0.6264\n",
      "Epoch 15/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2095 - accuracy: 0.6644 - val_loss: 0.2379 - val_accuracy: 0.6098\n",
      "Epoch 16/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2079 - accuracy: 0.6676 - val_loss: 0.2184 - val_accuracy: 0.6443\n",
      "Epoch 17/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2063 - accuracy: 0.6711 - val_loss: 0.2297 - val_accuracy: 0.6127\n",
      "Epoch 18/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2046 - accuracy: 0.6741 - val_loss: 0.2243 - val_accuracy: 0.6367\n",
      "Epoch 19/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2028 - accuracy: 0.6779 - val_loss: 0.2318 - val_accuracy: 0.6243\n",
      "Epoch 20/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.2012 - accuracy: 0.6815 - val_loss: 0.2254 - val_accuracy: 0.6382\n",
      "Epoch 21/5000\n",
      "5616/5616 [==============================] - 27s 5ms/step - loss: 0.1991 - accuracy: 0.6853 - val_loss: 0.2324 - val_accuracy: 0.6200\n",
      "Epoch 22/5000\n",
      "5616/5616 [==============================] - 28s 5ms/step - loss: 0.1976 - accuracy: 0.6880 - val_loss: 0.2382 - val_accuracy: 0.6186\n",
      "Epoch 23/5000\n",
      "5613/5616 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.6923Restoring model weights from the end of the best epoch: 3.\n",
      "5616/5616 [==============================] - 63s 11ms/step - loss: 0.1957 - accuracy: 0.6923 - val_loss: 0.2368 - val_accuracy: 0.6147\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/2000\n",
      "1404/1404 [==============================] - 10s 7ms/step - loss: 0.4609 - accuracy: 0.5081 - val_loss: 0.2250 - val_accuracy: 0.6126\n",
      "Epoch 2/2000\n",
      "1404/1404 [==============================] - 9s 7ms/step - loss: 0.2332 - accuracy: 0.6128 - val_loss: 0.2151 - val_accuracy: 0.6459\n",
      "Epoch 3/2000\n",
      "1404/1404 [==============================] - 9s 6ms/step - loss: 0.2288 - accuracy: 0.6224 - val_loss: 0.2371 - val_accuracy: 0.5649\n",
      "Epoch 4/2000\n",
      "1404/1404 [==============================] - 9s 6ms/step - loss: 0.2278 - accuracy: 0.6249 - val_loss: 0.2145 - val_accuracy: 0.6421\n",
      "Epoch 5/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2263 - accuracy: 0.6306 - val_loss: 0.2225 - val_accuracy: 0.6402\n",
      "Epoch 6/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2261 - accuracy: 0.6284 - val_loss: 0.2160 - val_accuracy: 0.6458\n",
      "Epoch 7/2000\n",
      "1404/1404 [==============================] - 9s 6ms/step - loss: 0.2256 - accuracy: 0.6310 - val_loss: 0.2273 - val_accuracy: 0.5966\n",
      "Epoch 8/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2247 - accuracy: 0.6317 - val_loss: 0.2300 - val_accuracy: 0.6200\n",
      "Epoch 9/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2246 - accuracy: 0.6339 - val_loss: 0.2195 - val_accuracy: 0.6261\n",
      "Epoch 10/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2243 - accuracy: 0.6333 - val_loss: 0.2340 - val_accuracy: 0.5975\n",
      "Epoch 11/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2236 - accuracy: 0.6354 - val_loss: 0.2120 - val_accuracy: 0.6481\n",
      "Epoch 12/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2233 - accuracy: 0.6368 - val_loss: 0.2362 - val_accuracy: 0.5699\n",
      "Epoch 13/2000\n",
      "1404/1404 [==============================] - 9s 6ms/step - loss: 0.2226 - accuracy: 0.6372 - val_loss: 0.2182 - val_accuracy: 0.6329\n",
      "Epoch 14/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2222 - accuracy: 0.6387 - val_loss: 0.2203 - val_accuracy: 0.6259\n",
      "Epoch 15/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2222 - accuracy: 0.6385 - val_loss: 0.2181 - val_accuracy: 0.6283\n",
      "Epoch 16/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2220 - accuracy: 0.6398 - val_loss: 0.2191 - val_accuracy: 0.6247\n",
      "Epoch 17/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2215 - accuracy: 0.6401 - val_loss: 0.2176 - val_accuracy: 0.6469\n",
      "Epoch 18/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2213 - accuracy: 0.6411 - val_loss: 0.2323 - val_accuracy: 0.5978\n",
      "Epoch 19/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2208 - accuracy: 0.6413 - val_loss: 0.2276 - val_accuracy: 0.5959\n",
      "Epoch 20/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2208 - accuracy: 0.6426 - val_loss: 0.2214 - val_accuracy: 0.6227\n",
      "Epoch 21/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2202 - accuracy: 0.6427 - val_loss: 0.2261 - val_accuracy: 0.6103\n",
      "Epoch 22/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2198 - accuracy: 0.6435 - val_loss: 0.2152 - val_accuracy: 0.6379\n",
      "Epoch 23/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2198 - accuracy: 0.6443 - val_loss: 0.2230 - val_accuracy: 0.6119\n",
      "Epoch 24/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2197 - accuracy: 0.6453 - val_loss: 0.2284 - val_accuracy: 0.6131\n",
      "Epoch 25/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2194 - accuracy: 0.6456 - val_loss: 0.2258 - val_accuracy: 0.6088\n",
      "Epoch 26/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2191 - accuracy: 0.6454 - val_loss: 0.2195 - val_accuracy: 0.6373\n",
      "Epoch 27/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2186 - accuracy: 0.6472 - val_loss: 0.2095 - val_accuracy: 0.6653\n",
      "Epoch 28/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2186 - accuracy: 0.6466 - val_loss: 0.2220 - val_accuracy: 0.6222\n",
      "Epoch 29/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2177 - accuracy: 0.6497 - val_loss: 0.2159 - val_accuracy: 0.6325\n",
      "Epoch 30/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2183 - accuracy: 0.6475 - val_loss: 0.2237 - val_accuracy: 0.6157\n",
      "Epoch 31/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2177 - accuracy: 0.6494 - val_loss: 0.2232 - val_accuracy: 0.6058\n",
      "Epoch 32/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2171 - accuracy: 0.6499 - val_loss: 0.2180 - val_accuracy: 0.6117\n",
      "Epoch 33/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2169 - accuracy: 0.6502 - val_loss: 0.2219 - val_accuracy: 0.6323\n",
      "Epoch 34/2000\n",
      "1404/1404 [==============================] - 10s 7ms/step - loss: 0.2169 - accuracy: 0.6507 - val_loss: 0.2327 - val_accuracy: 0.5786\n",
      "Epoch 35/2000\n",
      "1404/1404 [==============================] - 10s 7ms/step - loss: 0.2164 - accuracy: 0.6507 - val_loss: 0.2219 - val_accuracy: 0.6193\n",
      "Epoch 36/2000\n",
      "1404/1404 [==============================] - 9s 6ms/step - loss: 0.2159 - accuracy: 0.6507 - val_loss: 0.2176 - val_accuracy: 0.6550\n",
      "Epoch 37/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2159 - accuracy: 0.6525 - val_loss: 0.2224 - val_accuracy: 0.6272\n",
      "Epoch 38/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2158 - accuracy: 0.6521 - val_loss: 0.2371 - val_accuracy: 0.5898\n",
      "Epoch 39/2000\n",
      "1404/1404 [==============================] - 9s 6ms/step - loss: 0.2151 - accuracy: 0.6546 - val_loss: 0.2176 - val_accuracy: 0.6420\n",
      "Epoch 40/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2150 - accuracy: 0.6542 - val_loss: 0.2458 - val_accuracy: 0.5761\n",
      "Epoch 41/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2149 - accuracy: 0.6533 - val_loss: 0.2249 - val_accuracy: 0.6199\n",
      "Epoch 42/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2145 - accuracy: 0.6551 - val_loss: 0.2278 - val_accuracy: 0.5954\n",
      "Epoch 43/2000\n",
      "1404/1404 [==============================] - 8s 6ms/step - loss: 0.2141 - accuracy: 0.6568 - val_loss: 0.2279 - val_accuracy: 0.6213\n",
      "Epoch 44/2000\n",
      "1404/1404 [==============================] - 10s 7ms/step - loss: 0.2138 - accuracy: 0.6557 - val_loss: 0.2323 - val_accuracy: 0.5956\n",
      "Epoch 45/2000\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.2136 - accuracy: 0.6581 - val_loss: 0.2228 - val_accuracy: 0.6236\n",
      "Epoch 46/2000\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.2130 - accuracy: 0.6582 - val_loss: 0.2216 - val_accuracy: 0.6395\n",
      "Epoch 47/2000\n",
      "1399/1404 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.6582Restoring model weights from the end of the best epoch: 27.\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.2132 - accuracy: 0.6582 - val_loss: 0.2236 - val_accuracy: 0.6190\n",
      "Epoch 47: early stopping\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-06 22:30:13         2231\n",
      "metadata.json                                  2023-04-06 22:30:13           64\n",
      "variables.h5                                   2023-04-06 22:30:14       531800\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-06 22:30:14         2232\n",
      "metadata.json                                  2023-04-06 22:30:14           64\n",
      "variables.h5                                   2023-04-06 22:30:14       531800\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-06 22:30:14         2231\n",
      "metadata.json                                  2023-04-06 22:30:14           64\n",
      "variables.h5                                   2023-04-06 22:30:14       531800\n"
     ]
    }
   ],
   "source": [
    "ensemble_model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6144664616342898"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.get_score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-06 22:31:38         2231\n",
      "metadata.json                                  2023-04-06 22:31:38           64\n",
      "variables.h5                                   2023-04-06 22:31:38       531800\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-06 22:31:38         2232\n",
      "metadata.json                                  2023-04-06 22:31:38           64\n",
      "variables.h5                                   2023-04-06 22:31:38       531800\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-06 22:31:38         2231\n",
      "metadata.json                                  2023-04-06 22:31:38           64\n",
      "variables.h5                                   2023-04-06 22:31:38       531800\n"
     ]
    }
   ],
   "source": [
    "ensemble_model.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc61db7a6070c6c86b8447c28f804503118115942a6f856c38354ea7f041d17b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
