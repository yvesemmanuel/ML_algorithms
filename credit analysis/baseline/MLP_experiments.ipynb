{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yveem\\miniconda3\\envs\\machine_learning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Getting training & validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../databases/training.csv')\n",
    "df_valid = pd.read_csv('../databases/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(['IND_BOM_1_1'], axis=1), df_train['IND_BOM_1_1']\n",
    "X_val, y_val = df_valid.drop(['IND_BOM_1_1'], axis=1), df_valid['IND_BOM_1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parameters selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'hidden_layer_units': [32, 128, 256],\n",
    "    'hidden_layers': {\n",
    "        'low': 1,\n",
    "        'high': 2\n",
    "    },\n",
    "    'alpha': [0.0001, 0.01],\n",
    "    'max_iter': [2000, 5000, 10000],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'activation': ['tanh', 'relu', 'sigmoid'],\n",
    "    'optimizer': ['SGD', 'Adam'],\n",
    "    'output_activation': ['sigmoid', 'softmax'],\n",
    "    'loss_function': ['binary_crossentropy', 'mse'],\n",
    "    'dropout_rate': [0.5, 0.3, 0.02]\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.001\n",
    ")\n",
    "\n",
    "def objective(trial):\n",
    "    model = Sequential()\n",
    "    input_dimension = X_train.shape[1]\n",
    "    \n",
    "    model.add(\n",
    "        Dense(\n",
    "            input_dim=input_dimension,\n",
    "            units=trial.suggest_categorical(\n",
    "                'hidden_layer_units',\n",
    "                params['hidden_layer_units']\n",
    "            ),\n",
    "            activation=trial.suggest_categorical(\n",
    "                'activation',\n",
    "                params['activation']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    hidden_layers = trial.suggest_int('hidden_layers', params['hidden_layers']['low'], params['hidden_layers']['high'])\n",
    "    \n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=trial.suggest_categorical(\n",
    "                    'hidden_layer_units',\n",
    "                    params['hidden_layer_units']\n",
    "                ),\n",
    "                activation=trial.suggest_categorical(\n",
    "                    'activation',\n",
    "                    params['activation']\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                trial.suggest_categorical(\n",
    "                    'dropout_rate',\n",
    "                    params['dropout_rate']\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=1,\n",
    "            activation=trial.suggest_categorical(\n",
    "                'output_activation',\n",
    "                params['output_activation']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    alpha = trial.suggest_categorical('alpha', params['alpha'])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', params['optimizer'])\n",
    "\n",
    "    if optimizer_name == 'SGD':\n",
    "        optimizer = SGD(learning_rate=alpha)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        optimizer = Adam(learning_rate=alpha)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=trial.suggest_categorical('loss_function', params['loss_function']),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=trial.suggest_categorical(\n",
    "            'batch_size',\n",
    "            params['batch_size']\n",
    "        ),\n",
    "        epochs=trial.suggest_categorical(\n",
    "            'max_iter',\n",
    "            params['max_iter']\n",
    "        ),\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 00:36:55,804]\u001b[0m A new study created in memory with name: no-name-5ac79d01-cbbe-465e-b3bd-1db68f16a0d8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6334 - accuracy: 0.6487 - val_loss: 0.6077 - val_accuracy: 0.6681\n",
      "Epoch 2/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6110 - accuracy: 0.6657 - val_loss: 0.6034 - val_accuracy: 0.6710\n",
      "Epoch 3/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6061 - accuracy: 0.6707 - val_loss: 0.6013 - val_accuracy: 0.6724\n",
      "Epoch 4/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6039 - accuracy: 0.6723 - val_loss: 0.6004 - val_accuracy: 0.6740\n",
      "Epoch 5/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6020 - accuracy: 0.6735 - val_loss: 0.6007 - val_accuracy: 0.6726\n",
      "Epoch 6/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6008 - accuracy: 0.6751 - val_loss: 0.5991 - val_accuracy: 0.6746\n",
      "Epoch 7/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5998 - accuracy: 0.6761 - val_loss: 0.5984 - val_accuracy: 0.6753\n",
      "Epoch 8/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5986 - accuracy: 0.6771 - val_loss: 0.5977 - val_accuracy: 0.6754\n",
      "Epoch 9/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5978 - accuracy: 0.6778 - val_loss: 0.5972 - val_accuracy: 0.6758\n",
      "Epoch 10/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5968 - accuracy: 0.6793 - val_loss: 0.5961 - val_accuracy: 0.6770\n",
      "Epoch 11/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5958 - accuracy: 0.6797 - val_loss: 0.5956 - val_accuracy: 0.6779\n",
      "Epoch 12/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5952 - accuracy: 0.6798 - val_loss: 0.5952 - val_accuracy: 0.6778\n",
      "Epoch 13/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5940 - accuracy: 0.6806 - val_loss: 0.5947 - val_accuracy: 0.6782\n",
      "Epoch 14/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5936 - accuracy: 0.6807 - val_loss: 0.5942 - val_accuracy: 0.6784\n",
      "Epoch 15/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5932 - accuracy: 0.6807 - val_loss: 0.5936 - val_accuracy: 0.6789\n",
      "Epoch 16/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5926 - accuracy: 0.6818 - val_loss: 0.5940 - val_accuracy: 0.6789\n",
      "Epoch 17/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5918 - accuracy: 0.6825 - val_loss: 0.5930 - val_accuracy: 0.6794\n",
      "Epoch 18/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5913 - accuracy: 0.6825 - val_loss: 0.5927 - val_accuracy: 0.6800\n",
      "Epoch 19/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5910 - accuracy: 0.6828 - val_loss: 0.5927 - val_accuracy: 0.6792\n",
      "Epoch 20/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5904 - accuracy: 0.6828 - val_loss: 0.5928 - val_accuracy: 0.6791\n",
      "Epoch 21/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5901 - accuracy: 0.6834 - val_loss: 0.5921 - val_accuracy: 0.6800\n",
      "Epoch 22/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5897 - accuracy: 0.6831 - val_loss: 0.5917 - val_accuracy: 0.6807\n",
      "Epoch 23/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5896 - accuracy: 0.6837 - val_loss: 0.5916 - val_accuracy: 0.6804\n",
      "Epoch 24/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5890 - accuracy: 0.6831 - val_loss: 0.5916 - val_accuracy: 0.6801\n",
      "Epoch 25/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5887 - accuracy: 0.6848 - val_loss: 0.5915 - val_accuracy: 0.6800\n",
      "Epoch 26/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5883 - accuracy: 0.6848 - val_loss: 0.5913 - val_accuracy: 0.6808\n",
      "Epoch 27/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5879 - accuracy: 0.6854 - val_loss: 0.5909 - val_accuracy: 0.6809\n",
      "Epoch 28/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5878 - accuracy: 0.6855 - val_loss: 0.5914 - val_accuracy: 0.6800\n",
      "Epoch 29/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5873 - accuracy: 0.6846 - val_loss: 0.5918 - val_accuracy: 0.6810\n",
      "Epoch 30/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5870 - accuracy: 0.6858 - val_loss: 0.5925 - val_accuracy: 0.6779\n",
      "Epoch 31/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5869 - accuracy: 0.6854 - val_loss: 0.5907 - val_accuracy: 0.6812\n",
      "Epoch 32/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5863 - accuracy: 0.6854 - val_loss: 0.5917 - val_accuracy: 0.6810\n",
      "Epoch 33/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.5864 - accuracy: 0.6862 - val_loss: 0.5905 - val_accuracy: 0.6809\n",
      "Epoch 34/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5861 - accuracy: 0.6861 - val_loss: 0.5908 - val_accuracy: 0.6811\n",
      "Epoch 35/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5858 - accuracy: 0.6868 - val_loss: 0.5916 - val_accuracy: 0.6809\n",
      "Epoch 36/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.5859 - accuracy: 0.6864 - val_loss: 0.5903 - val_accuracy: 0.6814\n",
      "Epoch 37/10000\n",
      "3950/3953 [============================>.] - ETA: 0s - loss: 0.5855 - accuracy: 0.6869Restoring model weights from the end of the best epoch: 27.\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.5855 - accuracy: 0.6869 - val_loss: 0.5902 - val_accuracy: 0.6812\n",
      "Epoch 37: early stopping\n",
      "4257/4257 [==============================] - 5s 1ms/step - loss: 0.5909 - accuracy: 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 00:42:04,994]\u001b[0m Trial 0 finished with value: 0.5909279584884644 and parameters: {'hidden_layer_units': 32, 'activation': 'tanh', 'hidden_layers': 1, 'dropout_rate': 0.5, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'Adam', 'loss_function': 'binary_crossentropy', 'batch_size': 64, 'max_iter': 10000}. Best is trial 0 with value: 0.5909279584884644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6761 - accuracy: 0.5915 - val_loss: 0.6543 - val_accuracy: 0.6478\n",
      "Epoch 2/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6532 - accuracy: 0.6486 - val_loss: 0.6508 - val_accuracy: 0.6501\n",
      "Epoch 3/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6501 - accuracy: 0.6499 - val_loss: 0.6480 - val_accuracy: 0.6511\n",
      "Epoch 4/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6474 - accuracy: 0.6508 - val_loss: 0.6455 - val_accuracy: 0.6513\n",
      "Epoch 5/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6448 - accuracy: 0.6512 - val_loss: 0.6433 - val_accuracy: 0.6518\n",
      "Epoch 6/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6428 - accuracy: 0.6517 - val_loss: 0.6413 - val_accuracy: 0.6524\n",
      "Epoch 7/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6408 - accuracy: 0.6520 - val_loss: 0.6395 - val_accuracy: 0.6527\n",
      "Epoch 8/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6391 - accuracy: 0.6521 - val_loss: 0.6379 - val_accuracy: 0.6532\n",
      "Epoch 9/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6375 - accuracy: 0.6531 - val_loss: 0.6365 - val_accuracy: 0.6533\n",
      "Epoch 10/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6360 - accuracy: 0.6528 - val_loss: 0.6352 - val_accuracy: 0.6536\n",
      "Epoch 11/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6348 - accuracy: 0.6532 - val_loss: 0.6339 - val_accuracy: 0.6540\n",
      "Epoch 12/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6336 - accuracy: 0.6538 - val_loss: 0.6328 - val_accuracy: 0.6541\n",
      "Epoch 13/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6323 - accuracy: 0.6538 - val_loss: 0.6318 - val_accuracy: 0.6542\n",
      "Epoch 14/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6315 - accuracy: 0.6540 - val_loss: 0.6308 - val_accuracy: 0.6546\n",
      "Epoch 15/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6305 - accuracy: 0.6547 - val_loss: 0.6299 - val_accuracy: 0.6547\n",
      "Epoch 16/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6294 - accuracy: 0.6548 - val_loss: 0.6290 - val_accuracy: 0.6547\n",
      "Epoch 17/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6286 - accuracy: 0.6551 - val_loss: 0.6283 - val_accuracy: 0.6550\n",
      "Epoch 18/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6278 - accuracy: 0.6556 - val_loss: 0.6275 - val_accuracy: 0.6550\n",
      "Epoch 19/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6271 - accuracy: 0.6558 - val_loss: 0.6268 - val_accuracy: 0.6552\n",
      "Epoch 20/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6262 - accuracy: 0.6559 - val_loss: 0.6261 - val_accuracy: 0.6555\n",
      "Epoch 21/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6256 - accuracy: 0.6561 - val_loss: 0.6255 - val_accuracy: 0.6560\n",
      "Epoch 22/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6251 - accuracy: 0.6561 - val_loss: 0.6249 - val_accuracy: 0.6562\n",
      "Epoch 23/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6244 - accuracy: 0.6563 - val_loss: 0.6244 - val_accuracy: 0.6564\n",
      "Epoch 24/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6239 - accuracy: 0.6564 - val_loss: 0.6238 - val_accuracy: 0.6566\n",
      "Epoch 25/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6233 - accuracy: 0.6569 - val_loss: 0.6233 - val_accuracy: 0.6571\n",
      "Epoch 26/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6227 - accuracy: 0.6574 - val_loss: 0.6228 - val_accuracy: 0.6575\n",
      "Epoch 27/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6222 - accuracy: 0.6576 - val_loss: 0.6224 - val_accuracy: 0.6576\n",
      "Epoch 28/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6217 - accuracy: 0.6581 - val_loss: 0.6219 - val_accuracy: 0.6579\n",
      "Epoch 29/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6214 - accuracy: 0.6579 - val_loss: 0.6215 - val_accuracy: 0.6582\n",
      "Epoch 30/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6209 - accuracy: 0.6581 - val_loss: 0.6211 - val_accuracy: 0.6584\n",
      "Epoch 31/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6204 - accuracy: 0.6583 - val_loss: 0.6207 - val_accuracy: 0.6586\n",
      "Epoch 32/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6201 - accuracy: 0.6586 - val_loss: 0.6204 - val_accuracy: 0.6587\n",
      "Epoch 33/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6197 - accuracy: 0.6587 - val_loss: 0.6200 - val_accuracy: 0.6588\n",
      "Epoch 34/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6192 - accuracy: 0.6590 - val_loss: 0.6197 - val_accuracy: 0.6590\n",
      "Epoch 35/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6190 - accuracy: 0.6592 - val_loss: 0.6193 - val_accuracy: 0.6592\n",
      "Epoch 36/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6186 - accuracy: 0.6593 - val_loss: 0.6190 - val_accuracy: 0.6595\n",
      "Epoch 37/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6181 - accuracy: 0.6596 - val_loss: 0.6187 - val_accuracy: 0.6595\n",
      "Epoch 38/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6178 - accuracy: 0.6598 - val_loss: 0.6184 - val_accuracy: 0.6594\n",
      "Epoch 39/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6175 - accuracy: 0.6600 - val_loss: 0.6181 - val_accuracy: 0.6597\n",
      "Epoch 40/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6174 - accuracy: 0.6599 - val_loss: 0.6179 - val_accuracy: 0.6598\n",
      "Epoch 41/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6171 - accuracy: 0.6603 - val_loss: 0.6176 - val_accuracy: 0.6603\n",
      "Epoch 42/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6169 - accuracy: 0.6605 - val_loss: 0.6173 - val_accuracy: 0.6605\n",
      "Epoch 43/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6164 - accuracy: 0.6607 - val_loss: 0.6171 - val_accuracy: 0.6608\n",
      "Epoch 44/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6162 - accuracy: 0.6610 - val_loss: 0.6169 - val_accuracy: 0.6609\n",
      "Epoch 45/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6158 - accuracy: 0.6612 - val_loss: 0.6166 - val_accuracy: 0.6610\n",
      "Epoch 46/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6158 - accuracy: 0.6611 - val_loss: 0.6164 - val_accuracy: 0.6611\n",
      "Epoch 47/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6154 - accuracy: 0.6613 - val_loss: 0.6162 - val_accuracy: 0.6611\n",
      "Epoch 48/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6151 - accuracy: 0.6613 - val_loss: 0.6160 - val_accuracy: 0.6611\n",
      "Epoch 49/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6150 - accuracy: 0.6618 - val_loss: 0.6158 - val_accuracy: 0.6613\n",
      "Epoch 50/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6147 - accuracy: 0.6613 - val_loss: 0.6156 - val_accuracy: 0.6614\n",
      "Epoch 51/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6146 - accuracy: 0.6613 - val_loss: 0.6154 - val_accuracy: 0.6616\n",
      "Epoch 52/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6143 - accuracy: 0.6617 - val_loss: 0.6152 - val_accuracy: 0.6618\n",
      "Epoch 53/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6142 - accuracy: 0.6621 - val_loss: 0.6150 - val_accuracy: 0.6618\n",
      "Epoch 54/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6140 - accuracy: 0.6623 - val_loss: 0.6148 - val_accuracy: 0.6619\n",
      "Epoch 55/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6137 - accuracy: 0.6627 - val_loss: 0.6146 - val_accuracy: 0.6622\n",
      "Epoch 56/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6137 - accuracy: 0.6623 - val_loss: 0.6145 - val_accuracy: 0.6622\n",
      "Epoch 57/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6134 - accuracy: 0.6623 - val_loss: 0.6143 - val_accuracy: 0.6623\n",
      "Epoch 58/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6134 - accuracy: 0.6623 - val_loss: 0.6141 - val_accuracy: 0.6623\n",
      "Epoch 59/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6131 - accuracy: 0.6624 - val_loss: 0.6140 - val_accuracy: 0.6624\n",
      "Epoch 60/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6129 - accuracy: 0.6629 - val_loss: 0.6138 - val_accuracy: 0.6625\n",
      "Epoch 61/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6127 - accuracy: 0.6628 - val_loss: 0.6137 - val_accuracy: 0.6626\n",
      "Epoch 62/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6126 - accuracy: 0.6635 - val_loss: 0.6135 - val_accuracy: 0.6627\n",
      "Epoch 63/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6124 - accuracy: 0.6636 - val_loss: 0.6134 - val_accuracy: 0.6627\n",
      "Epoch 64/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6122 - accuracy: 0.6630 - val_loss: 0.6133 - val_accuracy: 0.6629\n",
      "Epoch 65/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6120 - accuracy: 0.6637 - val_loss: 0.6131 - val_accuracy: 0.6630\n",
      "Epoch 66/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6119 - accuracy: 0.6639 - val_loss: 0.6130 - val_accuracy: 0.6632\n",
      "Epoch 67/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6119 - accuracy: 0.6637 - val_loss: 0.6128 - val_accuracy: 0.6632\n",
      "Epoch 68/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6117 - accuracy: 0.6641 - val_loss: 0.6127 - val_accuracy: 0.6635\n",
      "Epoch 69/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6116 - accuracy: 0.6635 - val_loss: 0.6126 - val_accuracy: 0.6637\n",
      "Epoch 70/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6115 - accuracy: 0.6636 - val_loss: 0.6125 - val_accuracy: 0.6637\n",
      "Epoch 71/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6112 - accuracy: 0.6642 - val_loss: 0.6123 - val_accuracy: 0.6637\n",
      "Epoch 72/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6111 - accuracy: 0.6643 - val_loss: 0.6122 - val_accuracy: 0.6638\n",
      "Epoch 73/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6110 - accuracy: 0.6642 - val_loss: 0.6121 - val_accuracy: 0.6638\n",
      "Epoch 74/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6109 - accuracy: 0.6651 - val_loss: 0.6120 - val_accuracy: 0.6640\n",
      "Epoch 75/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6107 - accuracy: 0.6650 - val_loss: 0.6119 - val_accuracy: 0.6639\n",
      "Epoch 76/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6106 - accuracy: 0.6645 - val_loss: 0.6118 - val_accuracy: 0.6640\n",
      "Epoch 77/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6105 - accuracy: 0.6649 - val_loss: 0.6116 - val_accuracy: 0.6640\n",
      "Epoch 78/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6103 - accuracy: 0.6648 - val_loss: 0.6115 - val_accuracy: 0.6641\n",
      "Epoch 79/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6102 - accuracy: 0.6649 - val_loss: 0.6114 - val_accuracy: 0.6641\n",
      "Epoch 80/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6101 - accuracy: 0.6651 - val_loss: 0.6113 - val_accuracy: 0.6641\n",
      "Epoch 81/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6101 - accuracy: 0.6650 - val_loss: 0.6112 - val_accuracy: 0.6644\n",
      "Epoch 82/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6100 - accuracy: 0.6653 - val_loss: 0.6111 - val_accuracy: 0.6644\n",
      "Epoch 83/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6098 - accuracy: 0.6653 - val_loss: 0.6110 - val_accuracy: 0.6646\n",
      "Epoch 84/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6096 - accuracy: 0.6657 - val_loss: 0.6109 - val_accuracy: 0.6646\n",
      "Epoch 85/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6099 - accuracy: 0.6652 - val_loss: 0.6108 - val_accuracy: 0.6648\n",
      "Epoch 86/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6097 - accuracy: 0.6655 - val_loss: 0.6107 - val_accuracy: 0.6648\n",
      "Epoch 87/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6094 - accuracy: 0.6655 - val_loss: 0.6106 - val_accuracy: 0.6648\n",
      "Epoch 88/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6093 - accuracy: 0.6657 - val_loss: 0.6106 - val_accuracy: 0.6650\n",
      "Epoch 89/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6093 - accuracy: 0.6654 - val_loss: 0.6105 - val_accuracy: 0.6652\n",
      "Epoch 90/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6091 - accuracy: 0.6663 - val_loss: 0.6104 - val_accuracy: 0.6654\n",
      "Epoch 91/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6091 - accuracy: 0.6662 - val_loss: 0.6103 - val_accuracy: 0.6654\n",
      "Epoch 92/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6089 - accuracy: 0.6664 - val_loss: 0.6102 - val_accuracy: 0.6655\n",
      "Epoch 93/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6089 - accuracy: 0.6665 - val_loss: 0.6101 - val_accuracy: 0.6655\n",
      "Epoch 94/5000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6087 - accuracy: 0.6663 - val_loss: 0.6100 - val_accuracy: 0.6657\n",
      "Epoch 95/5000\n",
      "1960/1977 [============================>.] - ETA: 0s - loss: 0.6085 - accuracy: 0.6668Restoring model weights from the end of the best epoch: 85.\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6085 - accuracy: 0.6668 - val_loss: 0.6100 - val_accuracy: 0.6658\n",
      "Epoch 95: early stopping\n",
      "4257/4257 [==============================] - 6s 1ms/step - loss: 0.6108 - accuracy: 0.6648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 00:51:35,154]\u001b[0m Trial 1 finished with value: 0.6108361482620239 and parameters: {'hidden_layer_units': 128, 'activation': 'tanh', 'hidden_layers': 1, 'dropout_rate': 0.02, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'SGD', 'loss_function': 'binary_crossentropy', 'batch_size': 128, 'max_iter': 5000}. Best is trial 0 with value: 0.5909279584884644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 2/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 3/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 4/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 5/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 6/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 7/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 8/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 9/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 10/2000\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 11/2000\n",
      "1969/1977 [============================>.] - ETA: 0s - loss: 0.3446 - accuracy: 0.6554Restoring model weights from the end of the best epoch: 1.\n",
      "1977/1977 [==============================] - 5s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 11: early stopping\n",
      "4257/4257 [==============================] - 5s 1ms/step - loss: 0.3446 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 00:52:37,896]\u001b[0m Trial 2 finished with value: 0.34456583857536316 and parameters: {'hidden_layer_units': 32, 'activation': 'relu', 'hidden_layers': 2, 'dropout_rate': 0.5, 'output_activation': 'softmax', 'alpha': 0.01, 'optimizer': 'Adam', 'loss_function': 'mse', 'batch_size': 128, 'max_iter': 2000}. Best is trial 2 with value: 0.34456583857536316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.2166 - accuracy: 0.6553 - val_loss: 0.2124 - val_accuracy: 0.6554\n",
      "Epoch 2/5000\n",
      "3953/3953 [==============================] - 17s 4ms/step - loss: 0.2127 - accuracy: 0.6592 - val_loss: 0.2106 - val_accuracy: 0.6554\n",
      "Epoch 3/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.2114 - accuracy: 0.6618 - val_loss: 0.2063 - val_accuracy: 0.6721\n",
      "Epoch 4/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.2111 - accuracy: 0.6616 - val_loss: 0.2084 - val_accuracy: 0.6671\n",
      "Epoch 5/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.2110 - accuracy: 0.6626 - val_loss: 0.2086 - val_accuracy: 0.6554\n",
      "Epoch 6/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.2106 - accuracy: 0.6632 - val_loss: 0.2074 - val_accuracy: 0.6739\n",
      "Epoch 7/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.2105 - accuracy: 0.6637 - val_loss: 0.2064 - val_accuracy: 0.6742\n",
      "Epoch 8/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.2105 - accuracy: 0.6628 - val_loss: 0.2063 - val_accuracy: 0.6726\n",
      "Epoch 9/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.2104 - accuracy: 0.6639 - val_loss: 0.2085 - val_accuracy: 0.6599\n",
      "Epoch 10/5000\n",
      "3953/3953 [==============================] - 18s 5ms/step - loss: 0.2105 - accuracy: 0.6632 - val_loss: 0.2121 - val_accuracy: 0.6685\n",
      "Epoch 11/5000\n",
      "3953/3953 [==============================] - 18s 5ms/step - loss: 0.2107 - accuracy: 0.6631 - val_loss: 0.2115 - val_accuracy: 0.6630\n",
      "Epoch 12/5000\n",
      "3953/3953 [==============================] - 18s 5ms/step - loss: 0.2105 - accuracy: 0.6639 - val_loss: 0.2084 - val_accuracy: 0.6559\n",
      "Epoch 13/5000\n",
      "3951/3953 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.6623Restoring model weights from the end of the best epoch: 3.\n",
      "3953/3953 [==============================] - 18s 5ms/step - loss: 0.2105 - accuracy: 0.6623 - val_loss: 0.2066 - val_accuracy: 0.6689\n",
      "Epoch 13: early stopping\n",
      "4257/4257 [==============================] - 7s 2ms/step - loss: 0.2063 - accuracy: 0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 00:56:35,779]\u001b[0m Trial 3 finished with value: 0.20629926025867462 and parameters: {'hidden_layer_units': 256, 'activation': 'sigmoid', 'hidden_layers': 2, 'dropout_rate': 0.5, 'output_activation': 'sigmoid', 'alpha': 0.01, 'optimizer': 'Adam', 'loss_function': 'mse', 'batch_size': 64, 'max_iter': 5000}. Best is trial 3 with value: 0.20629926025867462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6472 - accuracy: 0.6537 - val_loss: 0.6410 - val_accuracy: 0.6554\n",
      "Epoch 2/5000\n",
      "7906/7906 [==============================] - 28s 3ms/step - loss: 0.6402 - accuracy: 0.6555 - val_loss: 0.6391 - val_accuracy: 0.6554\n",
      "Epoch 3/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6383 - accuracy: 0.6555 - val_loss: 0.6375 - val_accuracy: 0.6554\n",
      "Epoch 4/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6367 - accuracy: 0.6555 - val_loss: 0.6360 - val_accuracy: 0.6554\n",
      "Epoch 5/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6353 - accuracy: 0.6555 - val_loss: 0.6345 - val_accuracy: 0.6554\n",
      "Epoch 6/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6339 - accuracy: 0.6555 - val_loss: 0.6332 - val_accuracy: 0.6554\n",
      "Epoch 7/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6324 - accuracy: 0.6554 - val_loss: 0.6319 - val_accuracy: 0.6554\n",
      "Epoch 8/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6311 - accuracy: 0.6554 - val_loss: 0.6306 - val_accuracy: 0.6554\n",
      "Epoch 9/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6297 - accuracy: 0.6555 - val_loss: 0.6293 - val_accuracy: 0.6554\n",
      "Epoch 10/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6285 - accuracy: 0.6555 - val_loss: 0.6281 - val_accuracy: 0.6554\n",
      "Epoch 11/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6274 - accuracy: 0.6556 - val_loss: 0.6269 - val_accuracy: 0.6554\n",
      "Epoch 12/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6260 - accuracy: 0.6557 - val_loss: 0.6257 - val_accuracy: 0.6555\n",
      "Epoch 13/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6249 - accuracy: 0.6560 - val_loss: 0.6246 - val_accuracy: 0.6559\n",
      "Epoch 14/5000\n",
      "7906/7906 [==============================] - 28s 4ms/step - loss: 0.6236 - accuracy: 0.6563 - val_loss: 0.6234 - val_accuracy: 0.6561\n",
      "Epoch 15/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6223 - accuracy: 0.6567 - val_loss: 0.6223 - val_accuracy: 0.6567\n",
      "Epoch 16/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6213 - accuracy: 0.6572 - val_loss: 0.6213 - val_accuracy: 0.6572\n",
      "Epoch 17/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6201 - accuracy: 0.6578 - val_loss: 0.6203 - val_accuracy: 0.6576\n",
      "Epoch 18/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6191 - accuracy: 0.6583 - val_loss: 0.6193 - val_accuracy: 0.6582\n",
      "Epoch 19/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6181 - accuracy: 0.6589 - val_loss: 0.6184 - val_accuracy: 0.6587\n",
      "Epoch 20/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6171 - accuracy: 0.6595 - val_loss: 0.6175 - val_accuracy: 0.6591\n",
      "Epoch 21/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6162 - accuracy: 0.6602 - val_loss: 0.6167 - val_accuracy: 0.6598\n",
      "Epoch 22/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6153 - accuracy: 0.6609 - val_loss: 0.6160 - val_accuracy: 0.6600\n",
      "Epoch 23/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6146 - accuracy: 0.6611 - val_loss: 0.6153 - val_accuracy: 0.6609\n",
      "Epoch 24/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6139 - accuracy: 0.6617 - val_loss: 0.6146 - val_accuracy: 0.6615\n",
      "Epoch 25/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6131 - accuracy: 0.6627 - val_loss: 0.6140 - val_accuracy: 0.6617\n",
      "Epoch 26/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6127 - accuracy: 0.6629 - val_loss: 0.6135 - val_accuracy: 0.6625\n",
      "Epoch 27/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6120 - accuracy: 0.6633 - val_loss: 0.6130 - val_accuracy: 0.6630\n",
      "Epoch 28/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6115 - accuracy: 0.6639 - val_loss: 0.6125 - val_accuracy: 0.6633\n",
      "Epoch 29/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6110 - accuracy: 0.6644 - val_loss: 0.6120 - val_accuracy: 0.6638\n",
      "Epoch 30/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6106 - accuracy: 0.6639 - val_loss: 0.6116 - val_accuracy: 0.6638\n",
      "Epoch 31/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6101 - accuracy: 0.6648 - val_loss: 0.6112 - val_accuracy: 0.6641\n",
      "Epoch 32/5000\n",
      "7906/7906 [==============================] - 29s 4ms/step - loss: 0.6096 - accuracy: 0.6651 - val_loss: 0.6108 - val_accuracy: 0.6645\n",
      "Epoch 33/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6092 - accuracy: 0.6651 - val_loss: 0.6105 - val_accuracy: 0.6644\n",
      "Epoch 34/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6088 - accuracy: 0.6657 - val_loss: 0.6101 - val_accuracy: 0.6646\n",
      "Epoch 35/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6085 - accuracy: 0.6665 - val_loss: 0.6098 - val_accuracy: 0.6648\n",
      "Epoch 36/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6082 - accuracy: 0.6668 - val_loss: 0.6095 - val_accuracy: 0.6649\n",
      "Epoch 37/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6079 - accuracy: 0.6667 - val_loss: 0.6092 - val_accuracy: 0.6652\n",
      "Epoch 38/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6076 - accuracy: 0.6667 - val_loss: 0.6090 - val_accuracy: 0.6656\n",
      "Epoch 39/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6073 - accuracy: 0.6671 - val_loss: 0.6087 - val_accuracy: 0.6657\n",
      "Epoch 40/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6070 - accuracy: 0.6676 - val_loss: 0.6085 - val_accuracy: 0.6659\n",
      "Epoch 41/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6067 - accuracy: 0.6681 - val_loss: 0.6082 - val_accuracy: 0.6659\n",
      "Epoch 42/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6065 - accuracy: 0.6681 - val_loss: 0.6080 - val_accuracy: 0.6662\n",
      "Epoch 43/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6063 - accuracy: 0.6681 - val_loss: 0.6078 - val_accuracy: 0.6665\n",
      "Epoch 44/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6060 - accuracy: 0.6679 - val_loss: 0.6075 - val_accuracy: 0.6665\n",
      "Epoch 45/5000\n",
      "7906/7906 [==============================] - 30s 4ms/step - loss: 0.6058 - accuracy: 0.6685 - val_loss: 0.6073 - val_accuracy: 0.6665\n",
      "Epoch 46/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6054 - accuracy: 0.6690 - val_loss: 0.6071 - val_accuracy: 0.6668\n",
      "Epoch 47/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6053 - accuracy: 0.6687 - val_loss: 0.6069 - val_accuracy: 0.6669\n",
      "Epoch 48/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6052 - accuracy: 0.6687 - val_loss: 0.6067 - val_accuracy: 0.6668\n",
      "Epoch 49/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6049 - accuracy: 0.6690 - val_loss: 0.6066 - val_accuracy: 0.6670\n",
      "Epoch 50/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6048 - accuracy: 0.6691 - val_loss: 0.6064 - val_accuracy: 0.6672\n",
      "Epoch 51/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6045 - accuracy: 0.6694 - val_loss: 0.6062 - val_accuracy: 0.6673\n",
      "Epoch 52/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6044 - accuracy: 0.6695 - val_loss: 0.6060 - val_accuracy: 0.6674\n",
      "Epoch 53/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6042 - accuracy: 0.6697 - val_loss: 0.6059 - val_accuracy: 0.6672\n",
      "Epoch 54/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6039 - accuracy: 0.6695 - val_loss: 0.6057 - val_accuracy: 0.6674\n",
      "Epoch 55/5000\n",
      "7906/7906 [==============================] - 31s 4ms/step - loss: 0.6039 - accuracy: 0.6700 - val_loss: 0.6055 - val_accuracy: 0.6675\n",
      "Epoch 56/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6036 - accuracy: 0.6699 - val_loss: 0.6054 - val_accuracy: 0.6676\n",
      "Epoch 57/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6035 - accuracy: 0.6707 - val_loss: 0.6052 - val_accuracy: 0.6677\n",
      "Epoch 58/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6034 - accuracy: 0.6706 - val_loss: 0.6051 - val_accuracy: 0.6678\n",
      "Epoch 59/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6032 - accuracy: 0.6704 - val_loss: 0.6050 - val_accuracy: 0.6681\n",
      "Epoch 60/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6029 - accuracy: 0.6710 - val_loss: 0.6048 - val_accuracy: 0.6681\n",
      "Epoch 61/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6030 - accuracy: 0.6711 - val_loss: 0.6047 - val_accuracy: 0.6682\n",
      "Epoch 62/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6029 - accuracy: 0.6706 - val_loss: 0.6046 - val_accuracy: 0.6683\n",
      "Epoch 63/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6027 - accuracy: 0.6706 - val_loss: 0.6044 - val_accuracy: 0.6684\n",
      "Epoch 64/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6026 - accuracy: 0.6712 - val_loss: 0.6043 - val_accuracy: 0.6684\n",
      "Epoch 65/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6023 - accuracy: 0.6710 - val_loss: 0.6042 - val_accuracy: 0.6686\n",
      "Epoch 66/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6023 - accuracy: 0.6711 - val_loss: 0.6041 - val_accuracy: 0.6686\n",
      "Epoch 67/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6022 - accuracy: 0.6711 - val_loss: 0.6040 - val_accuracy: 0.6687\n",
      "Epoch 68/5000\n",
      "7906/7906 [==============================] - 35s 4ms/step - loss: 0.6019 - accuracy: 0.6716 - val_loss: 0.6038 - val_accuracy: 0.6688\n",
      "Epoch 69/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6019 - accuracy: 0.6718 - val_loss: 0.6038 - val_accuracy: 0.6688\n",
      "Epoch 70/5000\n",
      "7906/7906 [==============================] - 32s 4ms/step - loss: 0.6017 - accuracy: 0.6719 - val_loss: 0.6036 - val_accuracy: 0.6690\n",
      "Epoch 71/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6015 - accuracy: 0.6722 - val_loss: 0.6035 - val_accuracy: 0.6689\n",
      "Epoch 72/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6015 - accuracy: 0.6718 - val_loss: 0.6035 - val_accuracy: 0.6691\n",
      "Epoch 73/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6014 - accuracy: 0.6716 - val_loss: 0.6033 - val_accuracy: 0.6694\n",
      "Epoch 74/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6012 - accuracy: 0.6724 - val_loss: 0.6032 - val_accuracy: 0.6693\n",
      "Epoch 75/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6011 - accuracy: 0.6721 - val_loss: 0.6032 - val_accuracy: 0.6694\n",
      "Epoch 76/5000\n",
      "7906/7906 [==============================] - 33s 4ms/step - loss: 0.6010 - accuracy: 0.6723 - val_loss: 0.6031 - val_accuracy: 0.6697\n",
      "Epoch 77/5000\n",
      "7905/7906 [============================>.] - ETA: 0s - loss: 0.6010 - accuracy: 0.6722Restoring model weights from the end of the best epoch: 67.\n",
      "7906/7906 [==============================] - 34s 4ms/step - loss: 0.6010 - accuracy: 0.6722 - val_loss: 0.6030 - val_accuracy: 0.6695\n",
      "Epoch 77: early stopping\n",
      "4257/4257 [==============================] - 7s 2ms/step - loss: 0.6040 - accuracy: 0.6687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 01:35:34,181]\u001b[0m Trial 4 finished with value: 0.6039586663246155 and parameters: {'hidden_layer_units': 256, 'activation': 'relu', 'hidden_layers': 2, 'dropout_rate': 0.02, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'SGD', 'loss_function': 'binary_crossentropy', 'batch_size': 32, 'max_iter': 5000}. Best is trial 3 with value: 0.20629926025867462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1977/1977 [==============================] - 11s 5ms/step - loss: 0.6394 - accuracy: 0.6555 - val_loss: 0.6067 - val_accuracy: 0.6554\n",
      "Epoch 2/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6277 - accuracy: 0.6555 - val_loss: 0.6036 - val_accuracy: 0.6554\n",
      "Epoch 3/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6294 - accuracy: 0.6555 - val_loss: 0.6079 - val_accuracy: 0.6554\n",
      "Epoch 4/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6266 - accuracy: 0.6555 - val_loss: 0.6156 - val_accuracy: 0.6554\n",
      "Epoch 5/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6311 - accuracy: 0.6555 - val_loss: 0.6084 - val_accuracy: 0.6554\n",
      "Epoch 6/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6295 - accuracy: 0.6555 - val_loss: 0.6111 - val_accuracy: 0.6554\n",
      "Epoch 7/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6293 - accuracy: 0.6555 - val_loss: 0.6152 - val_accuracy: 0.6554\n",
      "Epoch 8/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6308 - accuracy: 0.6555 - val_loss: 0.6065 - val_accuracy: 0.6554\n",
      "Epoch 9/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6290 - accuracy: 0.6555 - val_loss: 0.6250 - val_accuracy: 0.6554\n",
      "Epoch 10/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6317 - accuracy: 0.6555 - val_loss: 0.6365 - val_accuracy: 0.6554\n",
      "Epoch 11/5000\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6296 - accuracy: 0.6555 - val_loss: 0.6497 - val_accuracy: 0.6554\n",
      "Epoch 12/5000\n",
      "1974/1977 [============================>.] - ETA: 0s - loss: 0.6298 - accuracy: 0.6554Restoring model weights from the end of the best epoch: 2.\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.6298 - accuracy: 0.6555 - val_loss: 0.6151 - val_accuracy: 0.6554\n",
      "Epoch 12: early stopping\n",
      "4257/4257 [==============================] - 6s 2ms/step - loss: 0.6036 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 01:37:41,476]\u001b[0m Trial 5 finished with value: 0.6036091446876526 and parameters: {'hidden_layer_units': 256, 'activation': 'tanh', 'hidden_layers': 1, 'dropout_rate': 0.3, 'output_activation': 'softmax', 'alpha': 0.01, 'optimizer': 'Adam', 'loss_function': 'binary_crossentropy', 'batch_size': 128, 'max_iter': 5000}. Best is trial 3 with value: 0.20629926025867462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6199 - accuracy: 0.6611 - val_loss: 0.6064 - val_accuracy: 0.6691\n",
      "Epoch 2/10000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.6036 - accuracy: 0.6721 - val_loss: 0.6028 - val_accuracy: 0.6718\n",
      "Epoch 3/10000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.6009 - accuracy: 0.6735 - val_loss: 0.6013 - val_accuracy: 0.6724\n",
      "Epoch 4/10000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.5998 - accuracy: 0.6746 - val_loss: 0.6019 - val_accuracy: 0.6717\n",
      "Epoch 5/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5992 - accuracy: 0.6752 - val_loss: 0.6023 - val_accuracy: 0.6719\n",
      "Epoch 6/10000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.5991 - accuracy: 0.6754 - val_loss: 0.6002 - val_accuracy: 0.6734\n",
      "Epoch 7/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5985 - accuracy: 0.6761 - val_loss: 0.6026 - val_accuracy: 0.6711\n",
      "Epoch 8/10000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.5985 - accuracy: 0.6759 - val_loss: 0.6003 - val_accuracy: 0.6739\n",
      "Epoch 9/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5980 - accuracy: 0.6761 - val_loss: 0.5996 - val_accuracy: 0.6748\n",
      "Epoch 10/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5976 - accuracy: 0.6763 - val_loss: 0.5989 - val_accuracy: 0.6745\n",
      "Epoch 11/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5973 - accuracy: 0.6771 - val_loss: 0.6001 - val_accuracy: 0.6738\n",
      "Epoch 12/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5967 - accuracy: 0.6778 - val_loss: 0.5985 - val_accuracy: 0.6751\n",
      "Epoch 13/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5965 - accuracy: 0.6776 - val_loss: 0.5994 - val_accuracy: 0.6747\n",
      "Epoch 14/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5959 - accuracy: 0.6781 - val_loss: 0.5976 - val_accuracy: 0.6758\n",
      "Epoch 15/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5953 - accuracy: 0.6788 - val_loss: 0.5981 - val_accuracy: 0.6752\n",
      "Epoch 16/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5947 - accuracy: 0.6788 - val_loss: 0.5963 - val_accuracy: 0.6770\n",
      "Epoch 17/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5940 - accuracy: 0.6797 - val_loss: 0.5958 - val_accuracy: 0.6772\n",
      "Epoch 18/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5935 - accuracy: 0.6801 - val_loss: 0.5957 - val_accuracy: 0.6773\n",
      "Epoch 19/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5931 - accuracy: 0.6798 - val_loss: 0.5948 - val_accuracy: 0.6782\n",
      "Epoch 20/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5924 - accuracy: 0.6811 - val_loss: 0.5952 - val_accuracy: 0.6780\n",
      "Epoch 21/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5921 - accuracy: 0.6805 - val_loss: 0.5942 - val_accuracy: 0.6782\n",
      "Epoch 22/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5916 - accuracy: 0.6811 - val_loss: 0.5941 - val_accuracy: 0.6783\n",
      "Epoch 23/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5912 - accuracy: 0.6810 - val_loss: 0.5935 - val_accuracy: 0.6790\n",
      "Epoch 24/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5909 - accuracy: 0.6818 - val_loss: 0.5935 - val_accuracy: 0.6785\n",
      "Epoch 25/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5906 - accuracy: 0.6818 - val_loss: 0.5940 - val_accuracy: 0.6783\n",
      "Epoch 26/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5901 - accuracy: 0.6823 - val_loss: 0.5928 - val_accuracy: 0.6798\n",
      "Epoch 27/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5899 - accuracy: 0.6824 - val_loss: 0.5926 - val_accuracy: 0.6793\n",
      "Epoch 28/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5896 - accuracy: 0.6826 - val_loss: 0.5921 - val_accuracy: 0.6798\n",
      "Epoch 29/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5894 - accuracy: 0.6830 - val_loss: 0.5922 - val_accuracy: 0.6795\n",
      "Epoch 30/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5891 - accuracy: 0.6831 - val_loss: 0.5918 - val_accuracy: 0.6799\n",
      "Epoch 31/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5887 - accuracy: 0.6835 - val_loss: 0.5916 - val_accuracy: 0.6800\n",
      "Epoch 32/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5885 - accuracy: 0.6833 - val_loss: 0.5919 - val_accuracy: 0.6796\n",
      "Epoch 33/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5884 - accuracy: 0.6829 - val_loss: 0.5913 - val_accuracy: 0.6802\n",
      "Epoch 34/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5881 - accuracy: 0.6841 - val_loss: 0.5930 - val_accuracy: 0.6779\n",
      "Epoch 35/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5877 - accuracy: 0.6843 - val_loss: 0.5911 - val_accuracy: 0.6808\n",
      "Epoch 36/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5876 - accuracy: 0.6843 - val_loss: 0.5909 - val_accuracy: 0.6810\n",
      "Epoch 37/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5872 - accuracy: 0.6848 - val_loss: 0.5908 - val_accuracy: 0.6807\n",
      "Epoch 38/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5872 - accuracy: 0.6846 - val_loss: 0.5909 - val_accuracy: 0.6804\n",
      "Epoch 39/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5869 - accuracy: 0.6848 - val_loss: 0.5906 - val_accuracy: 0.6808\n",
      "Epoch 40/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5868 - accuracy: 0.6847 - val_loss: 0.5904 - val_accuracy: 0.6812\n",
      "Epoch 41/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5866 - accuracy: 0.6846 - val_loss: 0.5904 - val_accuracy: 0.6811\n",
      "Epoch 42/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5862 - accuracy: 0.6850 - val_loss: 0.5903 - val_accuracy: 0.6814\n",
      "Epoch 43/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5861 - accuracy: 0.6852 - val_loss: 0.5914 - val_accuracy: 0.6800\n",
      "Epoch 44/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5859 - accuracy: 0.6854 - val_loss: 0.5905 - val_accuracy: 0.6810\n",
      "Epoch 45/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5856 - accuracy: 0.6855 - val_loss: 0.5899 - val_accuracy: 0.6811\n",
      "Epoch 46/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5854 - accuracy: 0.6859 - val_loss: 0.5905 - val_accuracy: 0.6806\n",
      "Epoch 47/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5853 - accuracy: 0.6858 - val_loss: 0.5899 - val_accuracy: 0.6818\n",
      "Epoch 48/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5851 - accuracy: 0.6862 - val_loss: 0.5897 - val_accuracy: 0.6813\n",
      "Epoch 49/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5849 - accuracy: 0.6865 - val_loss: 0.5898 - val_accuracy: 0.6815\n",
      "Epoch 50/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5847 - accuracy: 0.6864 - val_loss: 0.5896 - val_accuracy: 0.6823\n",
      "Epoch 51/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5845 - accuracy: 0.6865 - val_loss: 0.5897 - val_accuracy: 0.6819\n",
      "Epoch 52/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5843 - accuracy: 0.6867 - val_loss: 0.5897 - val_accuracy: 0.6816\n",
      "Epoch 53/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5843 - accuracy: 0.6870 - val_loss: 0.5895 - val_accuracy: 0.6818\n",
      "Epoch 54/10000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5841 - accuracy: 0.6873 - val_loss: 0.5893 - val_accuracy: 0.6814\n",
      "Epoch 55/10000\n",
      "3938/3953 [============================>.] - ETA: 0s - loss: 0.5836 - accuracy: 0.6872Restoring model weights from the end of the best epoch: 45.\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.5837 - accuracy: 0.6871 - val_loss: 0.5906 - val_accuracy: 0.6810\n",
      "Epoch 55: early stopping\n",
      "4257/4257 [==============================] - 6s 1ms/step - loss: 0.5899 - accuracy: 0.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 01:49:25,203]\u001b[0m Trial 6 finished with value: 0.5898686051368713 and parameters: {'hidden_layer_units': 128, 'activation': 'sigmoid', 'hidden_layers': 1, 'dropout_rate': 0.02, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'Adam', 'loss_function': 'binary_crossentropy', 'batch_size': 64, 'max_iter': 10000}. Best is trial 3 with value: 0.20629926025867462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.2084 - accuracy: 0.6705 - val_loss: 0.2075 - val_accuracy: 0.6711\n",
      "Epoch 2/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2053 - accuracy: 0.6759 - val_loss: 0.2056 - val_accuracy: 0.6734\n",
      "Epoch 3/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2044 - accuracy: 0.6778 - val_loss: 0.2044 - val_accuracy: 0.6765\n",
      "Epoch 4/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2038 - accuracy: 0.6796 - val_loss: 0.2069 - val_accuracy: 0.6723\n",
      "Epoch 5/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.2037 - accuracy: 0.6801 - val_loss: 0.2055 - val_accuracy: 0.6711\n",
      "Epoch 6/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2033 - accuracy: 0.6810 - val_loss: 0.2051 - val_accuracy: 0.6773\n",
      "Epoch 7/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2030 - accuracy: 0.6810 - val_loss: 0.2047 - val_accuracy: 0.6763\n",
      "Epoch 8/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.2027 - accuracy: 0.6821 - val_loss: 0.2046 - val_accuracy: 0.6754\n",
      "Epoch 9/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2026 - accuracy: 0.6826 - val_loss: 0.2041 - val_accuracy: 0.6781\n",
      "Epoch 10/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2025 - accuracy: 0.6825 - val_loss: 0.2052 - val_accuracy: 0.6732\n",
      "Epoch 11/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2023 - accuracy: 0.6823 - val_loss: 0.2040 - val_accuracy: 0.6771\n",
      "Epoch 12/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2021 - accuracy: 0.6829 - val_loss: 0.2047 - val_accuracy: 0.6767\n",
      "Epoch 13/5000\n",
      "3939/3953 [============================>.] - ETA: 0s - loss: 0.2019 - accuracy: 0.6829Restoring model weights from the end of the best epoch: 3.\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.2019 - accuracy: 0.6829 - val_loss: 0.2048 - val_accuracy: 0.6786\n",
      "Epoch 13: early stopping\n",
      "4257/4257 [==============================] - 5s 1ms/step - loss: 0.2044 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 01:51:23,357]\u001b[0m Trial 7 finished with value: 0.2043662667274475 and parameters: {'hidden_layer_units': 32, 'activation': 'sigmoid', 'hidden_layers': 1, 'dropout_rate': 0.02, 'output_activation': 'sigmoid', 'alpha': 0.01, 'optimizer': 'Adam', 'loss_function': 'mse', 'batch_size': 64, 'max_iter': 5000}. Best is trial 7 with value: 0.2043662667274475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.6049 - accuracy: 0.6555 - val_loss: 0.5981 - val_accuracy: 0.6554\n",
      "Epoch 2/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5965 - accuracy: 0.6555 - val_loss: 0.5986 - val_accuracy: 0.6554\n",
      "Epoch 3/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5953 - accuracy: 0.6555 - val_loss: 0.5958 - val_accuracy: 0.6554\n",
      "Epoch 4/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5935 - accuracy: 0.6555 - val_loss: 0.5957 - val_accuracy: 0.6554\n",
      "Epoch 5/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5929 - accuracy: 0.6555 - val_loss: 0.5952 - val_accuracy: 0.6554\n",
      "Epoch 6/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5922 - accuracy: 0.6555 - val_loss: 0.5943 - val_accuracy: 0.6554\n",
      "Epoch 7/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5916 - accuracy: 0.6555 - val_loss: 0.5937 - val_accuracy: 0.6554\n",
      "Epoch 8/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5913 - accuracy: 0.6555 - val_loss: 0.5955 - val_accuracy: 0.6554\n",
      "Epoch 9/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5903 - accuracy: 0.6555 - val_loss: 0.5952 - val_accuracy: 0.6554\n",
      "Epoch 10/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5903 - accuracy: 0.6555 - val_loss: 0.5930 - val_accuracy: 0.6554\n",
      "Epoch 11/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5899 - accuracy: 0.6555 - val_loss: 0.5962 - val_accuracy: 0.6554\n",
      "Epoch 12/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5892 - accuracy: 0.6555 - val_loss: 0.5943 - val_accuracy: 0.6554\n",
      "Epoch 13/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5889 - accuracy: 0.6555 - val_loss: 0.5941 - val_accuracy: 0.6554\n",
      "Epoch 14/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5884 - accuracy: 0.6555 - val_loss: 0.5933 - val_accuracy: 0.6554\n",
      "Epoch 15/2000\n",
      "3953/3953 [==============================] - 10s 3ms/step - loss: 0.5882 - accuracy: 0.6555 - val_loss: 0.5940 - val_accuracy: 0.6554\n",
      "Epoch 16/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5879 - accuracy: 0.6555 - val_loss: 0.5942 - val_accuracy: 0.6554\n",
      "Epoch 17/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5875 - accuracy: 0.6555 - val_loss: 0.5945 - val_accuracy: 0.6554\n",
      "Epoch 18/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5874 - accuracy: 0.6555 - val_loss: 0.5946 - val_accuracy: 0.6554\n",
      "Epoch 19/2000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5873 - accuracy: 0.6555 - val_loss: 0.5935 - val_accuracy: 0.6554\n",
      "Epoch 20/2000\n",
      "3928/3953 [============================>.] - ETA: 0s - loss: 0.5869 - accuracy: 0.6554Restoring model weights from the end of the best epoch: 10.\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.5868 - accuracy: 0.6555 - val_loss: 0.5931 - val_accuracy: 0.6554\n",
      "Epoch 20: early stopping\n",
      "4257/4257 [==============================] - 5s 1ms/step - loss: 0.5930 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 01:54:44,219]\u001b[0m Trial 8 finished with value: 0.5930061936378479 and parameters: {'hidden_layer_units': 32, 'activation': 'sigmoid', 'hidden_layers': 2, 'dropout_rate': 0.02, 'output_activation': 'softmax', 'alpha': 0.01, 'optimizer': 'Adam', 'loss_function': 'binary_crossentropy', 'batch_size': 64, 'max_iter': 2000}. Best is trial 7 with value: 0.2043662667274475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6511 - accuracy: 0.6506 - val_loss: 0.6434 - val_accuracy: 0.6554\n",
      "Epoch 2/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6450 - accuracy: 0.6555 - val_loss: 0.6449 - val_accuracy: 0.6554\n",
      "Epoch 3/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6445 - accuracy: 0.6555 - val_loss: 0.6431 - val_accuracy: 0.6554\n",
      "Epoch 4/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6443 - accuracy: 0.6555 - val_loss: 0.6427 - val_accuracy: 0.6554\n",
      "Epoch 5/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6435 - accuracy: 0.6555 - val_loss: 0.6420 - val_accuracy: 0.6554\n",
      "Epoch 6/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6425 - accuracy: 0.6554 - val_loss: 0.6393 - val_accuracy: 0.6554\n",
      "Epoch 7/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6413 - accuracy: 0.6554 - val_loss: 0.6367 - val_accuracy: 0.6554\n",
      "Epoch 8/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6389 - accuracy: 0.6554 - val_loss: 0.6331 - val_accuracy: 0.6554\n",
      "Epoch 9/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6357 - accuracy: 0.6555 - val_loss: 0.6287 - val_accuracy: 0.6554\n",
      "Epoch 10/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6323 - accuracy: 0.6550 - val_loss: 0.6253 - val_accuracy: 0.6555\n",
      "Epoch 11/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6282 - accuracy: 0.6558 - val_loss: 0.6206 - val_accuracy: 0.6561\n",
      "Epoch 12/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6247 - accuracy: 0.6574 - val_loss: 0.6177 - val_accuracy: 0.6561\n",
      "Epoch 13/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6222 - accuracy: 0.6580 - val_loss: 0.6155 - val_accuracy: 0.6582\n",
      "Epoch 14/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6192 - accuracy: 0.6598 - val_loss: 0.6133 - val_accuracy: 0.6611\n",
      "Epoch 15/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6174 - accuracy: 0.6599 - val_loss: 0.6120 - val_accuracy: 0.6620\n",
      "Epoch 16/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6160 - accuracy: 0.6603 - val_loss: 0.6109 - val_accuracy: 0.6649\n",
      "Epoch 17/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6147 - accuracy: 0.6615 - val_loss: 0.6125 - val_accuracy: 0.6598\n",
      "Epoch 18/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6135 - accuracy: 0.6620 - val_loss: 0.6092 - val_accuracy: 0.6661\n",
      "Epoch 19/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6126 - accuracy: 0.6630 - val_loss: 0.6085 - val_accuracy: 0.6665\n",
      "Epoch 20/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6116 - accuracy: 0.6642 - val_loss: 0.6080 - val_accuracy: 0.6664\n",
      "Epoch 21/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6111 - accuracy: 0.6639 - val_loss: 0.6080 - val_accuracy: 0.6672\n",
      "Epoch 22/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6101 - accuracy: 0.6647 - val_loss: 0.6073 - val_accuracy: 0.6661\n",
      "Epoch 23/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6097 - accuracy: 0.6653 - val_loss: 0.6065 - val_accuracy: 0.6674\n",
      "Epoch 24/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6094 - accuracy: 0.6655 - val_loss: 0.6066 - val_accuracy: 0.6675\n",
      "Epoch 25/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6087 - accuracy: 0.6656 - val_loss: 0.6059 - val_accuracy: 0.6673\n",
      "Epoch 26/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6085 - accuracy: 0.6666 - val_loss: 0.6055 - val_accuracy: 0.6679\n",
      "Epoch 27/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6073 - accuracy: 0.6668 - val_loss: 0.6051 - val_accuracy: 0.6676\n",
      "Epoch 28/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6073 - accuracy: 0.6672 - val_loss: 0.6049 - val_accuracy: 0.6680\n",
      "Epoch 29/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6070 - accuracy: 0.6669 - val_loss: 0.6046 - val_accuracy: 0.6684\n",
      "Epoch 30/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6065 - accuracy: 0.6673 - val_loss: 0.6051 - val_accuracy: 0.6673\n",
      "Epoch 31/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6065 - accuracy: 0.6680 - val_loss: 0.6044 - val_accuracy: 0.6676\n",
      "Epoch 32/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6063 - accuracy: 0.6677 - val_loss: 0.6040 - val_accuracy: 0.6685\n",
      "Epoch 33/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6057 - accuracy: 0.6686 - val_loss: 0.6039 - val_accuracy: 0.6680\n",
      "Epoch 34/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6055 - accuracy: 0.6681 - val_loss: 0.6035 - val_accuracy: 0.6683\n",
      "Epoch 35/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6052 - accuracy: 0.6687 - val_loss: 0.6035 - val_accuracy: 0.6694\n",
      "Epoch 36/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6048 - accuracy: 0.6684 - val_loss: 0.6033 - val_accuracy: 0.6683\n",
      "Epoch 37/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6046 - accuracy: 0.6696 - val_loss: 0.6029 - val_accuracy: 0.6695\n",
      "Epoch 38/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6044 - accuracy: 0.6686 - val_loss: 0.6029 - val_accuracy: 0.6696\n",
      "Epoch 39/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6044 - accuracy: 0.6692 - val_loss: 0.6028 - val_accuracy: 0.6698\n",
      "Epoch 40/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6037 - accuracy: 0.6698 - val_loss: 0.6025 - val_accuracy: 0.6700\n",
      "Epoch 41/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6039 - accuracy: 0.6697 - val_loss: 0.6024 - val_accuracy: 0.6700\n",
      "Epoch 42/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6042 - accuracy: 0.6694 - val_loss: 0.6024 - val_accuracy: 0.6688\n",
      "Epoch 43/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6036 - accuracy: 0.6700 - val_loss: 0.6021 - val_accuracy: 0.6703\n",
      "Epoch 44/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6035 - accuracy: 0.6706 - val_loss: 0.6023 - val_accuracy: 0.6689\n",
      "Epoch 45/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6031 - accuracy: 0.6707 - val_loss: 0.6020 - val_accuracy: 0.6693\n",
      "Epoch 46/5000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.6033 - accuracy: 0.6702 - val_loss: 0.6022 - val_accuracy: 0.6691\n",
      "Epoch 47/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6030 - accuracy: 0.6704 - val_loss: 0.6017 - val_accuracy: 0.6703\n",
      "Epoch 48/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6029 - accuracy: 0.6716 - val_loss: 0.6017 - val_accuracy: 0.6693\n",
      "Epoch 49/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6028 - accuracy: 0.6702 - val_loss: 0.6015 - val_accuracy: 0.6709\n",
      "Epoch 50/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6025 - accuracy: 0.6705 - val_loss: 0.6014 - val_accuracy: 0.6704\n",
      "Epoch 51/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6022 - accuracy: 0.6716 - val_loss: 0.6017 - val_accuracy: 0.6714\n",
      "Epoch 52/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6024 - accuracy: 0.6708 - val_loss: 0.6013 - val_accuracy: 0.6716\n",
      "Epoch 53/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6022 - accuracy: 0.6711 - val_loss: 0.6011 - val_accuracy: 0.6715\n",
      "Epoch 54/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6021 - accuracy: 0.6710 - val_loss: 0.6011 - val_accuracy: 0.6707\n",
      "Epoch 55/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6020 - accuracy: 0.6712 - val_loss: 0.6010 - val_accuracy: 0.6717\n",
      "Epoch 56/5000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6019 - accuracy: 0.6717 - val_loss: 0.6010 - val_accuracy: 0.6719\n",
      "Epoch 57/5000\n",
      "7894/7906 [============================>.] - ETA: 0s - loss: 0.6019 - accuracy: 0.6711Restoring model weights from the end of the best epoch: 47.\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.6018 - accuracy: 0.6712 - val_loss: 0.6009 - val_accuracy: 0.6714\n",
      "Epoch 57: early stopping\n",
      "4257/4257 [==============================] - 7s 2ms/step - loss: 0.6017 - accuracy: 0.6703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-31 02:15:55,773]\u001b[0m Trial 9 finished with value: 0.6017345190048218 and parameters: {'hidden_layer_units': 128, 'activation': 'sigmoid', 'hidden_layers': 1, 'dropout_rate': 0.5, 'output_activation': 'sigmoid', 'alpha': 0.01, 'optimizer': 'SGD', 'loss_function': 'binary_crossentropy', 'batch_size': 32, 'max_iter': 5000}. Best is trial 7 with value: 0.2043662667274475.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "n_trials = 10\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'hidden_layer_units': 32, 'activation': 'sigmoid', 'hidden_layers': 1, 'dropout_rate': 0.02, 'output_activation': 'sigmoid', 'alpha': 0.01, 'optimizer': 'Adam', 'loss_function': 'mse', 'batch_size': 64, 'max_iter': 5000}\n",
      "Best objective value:  0.2043662667274475\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters: ', study.best_params)\n",
    "print('Best objective value: ', study.best_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Saving study**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./optuna_studies/mlp_study.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = './optuna_studies/mlp_study.pkl'\n",
    "\n",
    "joblib.dump(study, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc61db7a6070c6c86b8447c28f804503118115942a6f856c38354ea7f041d17b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
