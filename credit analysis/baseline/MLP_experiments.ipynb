{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yveem\\miniconda3\\envs\\machine_learning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Getting training & validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../databases/training.csv')\n",
    "df_valid = pd.read_csv('../databases/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(['IND_BOM_1_1'], axis=1), df_train['IND_BOM_1_1']\n",
    "X_val, y_val = df_valid.drop(['IND_BOM_1_1'], axis=1), df_valid['IND_BOM_1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parameters selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'hidden_layer_units': [32, 128, 256],\n",
    "    'hidden_layers': {\n",
    "        'low': 1,\n",
    "        'high': 2\n",
    "    },\n",
    "    'alpha': [0.0001, 0.01],\n",
    "    'max_iter': [2000, 5000, 10000],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'activation': ['tanh', 'relu', 'sigmoid'],\n",
    "    'optimizer': ['SGD', 'Adam'],\n",
    "    'output_activation': ['sigmoid', 'softmax'],\n",
    "    'loss_function': ['binary_crossentropy', 'mse']    \n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.001\n",
    ")\n",
    "\n",
    "def objective(trial):\n",
    "    model = Sequential()\n",
    "    input_dimension = X_train.shape[1]\n",
    "    \n",
    "    model.add(\n",
    "        Dense(\n",
    "            input_dim=input_dimension,\n",
    "            units=trial.suggest_categorical(\n",
    "                'hidden_layer_units',\n",
    "                params['hidden_layer_units']\n",
    "            ),\n",
    "            activation=trial.suggest_categorical(\n",
    "                'activation',\n",
    "                params['activation']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    hidden_layers = trial.suggest_int('hidden_layers', params['hidden_layers']['low'], params['hidden_layers']['high'])\n",
    "    \n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=trial.suggest_categorical(\n",
    "                    'hidden_layer_units',\n",
    "                    params['hidden_layer_units']\n",
    "                ),\n",
    "                activation=trial.suggest_categorical(\n",
    "                    'activation',\n",
    "                    params['activation']\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=1,\n",
    "            activation=trial.suggest_categorical(\n",
    "                'output_activation',\n",
    "                params['output_activation']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    alpha = trial.suggest_categorical('alpha', params['alpha'])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', params['optimizer'])\n",
    "\n",
    "    if optimizer_name == 'SGD':\n",
    "        optimizer = SGD(learning_rate=alpha)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        optimizer = Adam(learning_rate=alpha)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=trial.suggest_categorical('loss_function', params['loss_function']),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=trial.suggest_categorical(\n",
    "            'batch_size',\n",
    "            params['batch_size']\n",
    "        ),\n",
    "        epochs=trial.suggest_categorical(\n",
    "            'max_iter',\n",
    "            params['max_iter']\n",
    "        ),\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 21:21:53,923]\u001b[0m A new study created in memory with name: no-name-ed646e20-eb50-4675-bd92-317946ed65e4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6516 - accuracy: 0.6541 - val_loss: 0.6465 - val_accuracy: 0.6554\n",
      "Epoch 2/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6449 - accuracy: 0.6555 - val_loss: 0.6442 - val_accuracy: 0.6554\n",
      "Epoch 3/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6430 - accuracy: 0.6555 - val_loss: 0.6424 - val_accuracy: 0.6554\n",
      "Epoch 4/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6413 - accuracy: 0.6555 - val_loss: 0.6408 - val_accuracy: 0.6554\n",
      "Epoch 5/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6398 - accuracy: 0.6555 - val_loss: 0.6394 - val_accuracy: 0.6554\n",
      "Epoch 6/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6384 - accuracy: 0.6555 - val_loss: 0.6380 - val_accuracy: 0.6554\n",
      "Epoch 7/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6371 - accuracy: 0.6555 - val_loss: 0.6368 - val_accuracy: 0.6554\n",
      "Epoch 8/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6359 - accuracy: 0.6555 - val_loss: 0.6357 - val_accuracy: 0.6554\n",
      "Epoch 9/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6348 - accuracy: 0.6555 - val_loss: 0.6346 - val_accuracy: 0.6554\n",
      "Epoch 10/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6337 - accuracy: 0.6555 - val_loss: 0.6335 - val_accuracy: 0.6554\n",
      "Epoch 11/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6327 - accuracy: 0.6555 - val_loss: 0.6325 - val_accuracy: 0.6554\n",
      "Epoch 12/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.6317 - accuracy: 0.6555 - val_loss: 0.6316 - val_accuracy: 0.6554\n",
      "Epoch 13/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6308 - accuracy: 0.6555 - val_loss: 0.6307 - val_accuracy: 0.6554\n",
      "Epoch 14/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6299 - accuracy: 0.6555 - val_loss: 0.6298 - val_accuracy: 0.6554\n",
      "Epoch 15/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6290 - accuracy: 0.6555 - val_loss: 0.6289 - val_accuracy: 0.6555\n",
      "Epoch 16/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6281 - accuracy: 0.6556 - val_loss: 0.6281 - val_accuracy: 0.6555\n",
      "Epoch 17/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6273 - accuracy: 0.6556 - val_loss: 0.6273 - val_accuracy: 0.6556\n",
      "Epoch 18/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6265 - accuracy: 0.6558 - val_loss: 0.6265 - val_accuracy: 0.6556\n",
      "Epoch 19/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6257 - accuracy: 0.6558 - val_loss: 0.6257 - val_accuracy: 0.6558\n",
      "Epoch 20/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6249 - accuracy: 0.6560 - val_loss: 0.6250 - val_accuracy: 0.6561\n",
      "Epoch 21/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6241 - accuracy: 0.6562 - val_loss: 0.6243 - val_accuracy: 0.6564\n",
      "Epoch 22/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6234 - accuracy: 0.6565 - val_loss: 0.6236 - val_accuracy: 0.6567\n",
      "Epoch 23/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6227 - accuracy: 0.6569 - val_loss: 0.6229 - val_accuracy: 0.6571\n",
      "Epoch 24/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6220 - accuracy: 0.6570 - val_loss: 0.6223 - val_accuracy: 0.6575\n",
      "Epoch 25/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6213 - accuracy: 0.6574 - val_loss: 0.6217 - val_accuracy: 0.6578\n",
      "Epoch 26/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6207 - accuracy: 0.6578 - val_loss: 0.6211 - val_accuracy: 0.6583\n",
      "Epoch 27/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6201 - accuracy: 0.6582 - val_loss: 0.6205 - val_accuracy: 0.6585\n",
      "Epoch 28/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6195 - accuracy: 0.6590 - val_loss: 0.6200 - val_accuracy: 0.6588\n",
      "Epoch 29/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6189 - accuracy: 0.6593 - val_loss: 0.6195 - val_accuracy: 0.6592\n",
      "Epoch 30/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6183 - accuracy: 0.6599 - val_loss: 0.6189 - val_accuracy: 0.6593\n",
      "Epoch 31/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6178 - accuracy: 0.6603 - val_loss: 0.6185 - val_accuracy: 0.6596\n",
      "Epoch 32/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6173 - accuracy: 0.6607 - val_loss: 0.6180 - val_accuracy: 0.6598\n",
      "Epoch 33/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6168 - accuracy: 0.6610 - val_loss: 0.6175 - val_accuracy: 0.6603\n",
      "Epoch 34/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6163 - accuracy: 0.6616 - val_loss: 0.6171 - val_accuracy: 0.6605\n",
      "Epoch 35/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6158 - accuracy: 0.6619 - val_loss: 0.6167 - val_accuracy: 0.6606\n",
      "Epoch 36/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6154 - accuracy: 0.6623 - val_loss: 0.6163 - val_accuracy: 0.6608\n",
      "Epoch 37/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6149 - accuracy: 0.6625 - val_loss: 0.6159 - val_accuracy: 0.6608\n",
      "Epoch 38/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6145 - accuracy: 0.6628 - val_loss: 0.6156 - val_accuracy: 0.6612\n",
      "Epoch 39/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6141 - accuracy: 0.6631 - val_loss: 0.6152 - val_accuracy: 0.6613\n",
      "Epoch 40/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6137 - accuracy: 0.6633 - val_loss: 0.6149 - val_accuracy: 0.6617\n",
      "Epoch 41/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6134 - accuracy: 0.6635 - val_loss: 0.6146 - val_accuracy: 0.6620\n",
      "Epoch 42/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6130 - accuracy: 0.6640 - val_loss: 0.6143 - val_accuracy: 0.6621\n",
      "Epoch 43/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6127 - accuracy: 0.6638 - val_loss: 0.6140 - val_accuracy: 0.6625\n",
      "Epoch 44/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6123 - accuracy: 0.6641 - val_loss: 0.6137 - val_accuracy: 0.6625\n",
      "Epoch 45/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.6120 - accuracy: 0.6642 - val_loss: 0.6134 - val_accuracy: 0.6628\n",
      "Epoch 46/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6117 - accuracy: 0.6646 - val_loss: 0.6131 - val_accuracy: 0.6630\n",
      "Epoch 47/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6114 - accuracy: 0.6647 - val_loss: 0.6129 - val_accuracy: 0.6632\n",
      "Epoch 48/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6111 - accuracy: 0.6649 - val_loss: 0.6126 - val_accuracy: 0.6634\n",
      "Epoch 49/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6109 - accuracy: 0.6650 - val_loss: 0.6124 - val_accuracy: 0.6637\n",
      "Epoch 50/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6106 - accuracy: 0.6650 - val_loss: 0.6122 - val_accuracy: 0.6635\n",
      "Epoch 51/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6103 - accuracy: 0.6652 - val_loss: 0.6120 - val_accuracy: 0.6637\n",
      "Epoch 52/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6101 - accuracy: 0.6655 - val_loss: 0.6118 - val_accuracy: 0.6636\n",
      "Epoch 53/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6099 - accuracy: 0.6655 - val_loss: 0.6116 - val_accuracy: 0.6639\n",
      "Epoch 54/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6096 - accuracy: 0.6656 - val_loss: 0.6114 - val_accuracy: 0.6639\n",
      "Epoch 55/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6094 - accuracy: 0.6657 - val_loss: 0.6112 - val_accuracy: 0.6639\n",
      "Epoch 56/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6092 - accuracy: 0.6658 - val_loss: 0.6110 - val_accuracy: 0.6642\n",
      "Epoch 57/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6090 - accuracy: 0.6659 - val_loss: 0.6108 - val_accuracy: 0.6643\n",
      "Epoch 58/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6088 - accuracy: 0.6661 - val_loss: 0.6106 - val_accuracy: 0.6646\n",
      "Epoch 59/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6086 - accuracy: 0.6663 - val_loss: 0.6104 - val_accuracy: 0.6648\n",
      "Epoch 60/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6084 - accuracy: 0.6662 - val_loss: 0.6103 - val_accuracy: 0.6649\n",
      "Epoch 61/5000\n",
      "3953/3953 [==============================] - 18s 4ms/step - loss: 0.6082 - accuracy: 0.6665 - val_loss: 0.6101 - val_accuracy: 0.6649\n",
      "Epoch 62/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6080 - accuracy: 0.6666 - val_loss: 0.6100 - val_accuracy: 0.6651\n",
      "Epoch 63/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6078 - accuracy: 0.6668 - val_loss: 0.6098 - val_accuracy: 0.6651\n",
      "Epoch 64/5000\n",
      "3953/3953 [==============================] - 17s 4ms/step - loss: 0.6076 - accuracy: 0.6670 - val_loss: 0.6096 - val_accuracy: 0.6649\n",
      "Epoch 65/5000\n",
      "3953/3953 [==============================] - 17s 4ms/step - loss: 0.6075 - accuracy: 0.6670 - val_loss: 0.6095 - val_accuracy: 0.6651\n",
      "Epoch 66/5000\n",
      "3953/3953 [==============================] - 17s 4ms/step - loss: 0.6073 - accuracy: 0.6672 - val_loss: 0.6094 - val_accuracy: 0.6656\n",
      "Epoch 67/5000\n",
      "3953/3953 [==============================] - 17s 4ms/step - loss: 0.6071 - accuracy: 0.6674 - val_loss: 0.6092 - val_accuracy: 0.6653\n",
      "Epoch 68/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6069 - accuracy: 0.6675 - val_loss: 0.6091 - val_accuracy: 0.6655\n",
      "Epoch 69/5000\n",
      "3953/3953 [==============================] - 24s 6ms/step - loss: 0.6068 - accuracy: 0.6675 - val_loss: 0.6089 - val_accuracy: 0.6658\n",
      "Epoch 70/5000\n",
      "3953/3953 [==============================] - 18s 5ms/step - loss: 0.6066 - accuracy: 0.6675 - val_loss: 0.6089 - val_accuracy: 0.6657\n",
      "Epoch 71/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6065 - accuracy: 0.6679 - val_loss: 0.6087 - val_accuracy: 0.6660\n",
      "Epoch 72/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6063 - accuracy: 0.6677 - val_loss: 0.6086 - val_accuracy: 0.6660\n",
      "Epoch 73/5000\n",
      "3953/3953 [==============================] - 17s 4ms/step - loss: 0.6062 - accuracy: 0.6681 - val_loss: 0.6084 - val_accuracy: 0.6662\n",
      "Epoch 74/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6061 - accuracy: 0.6683 - val_loss: 0.6083 - val_accuracy: 0.6663\n",
      "Epoch 75/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6059 - accuracy: 0.6683 - val_loss: 0.6082 - val_accuracy: 0.6664\n",
      "Epoch 76/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6058 - accuracy: 0.6684 - val_loss: 0.6082 - val_accuracy: 0.6663\n",
      "Epoch 77/5000\n",
      "3953/3953 [==============================] - 17s 4ms/step - loss: 0.6057 - accuracy: 0.6684 - val_loss: 0.6080 - val_accuracy: 0.6668\n",
      "Epoch 78/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6055 - accuracy: 0.6687 - val_loss: 0.6079 - val_accuracy: 0.6670\n",
      "Epoch 79/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6054 - accuracy: 0.6688 - val_loss: 0.6078 - val_accuracy: 0.6669\n",
      "Epoch 80/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6053 - accuracy: 0.6688 - val_loss: 0.6076 - val_accuracy: 0.6671\n",
      "Epoch 81/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6051 - accuracy: 0.6690 - val_loss: 0.6075 - val_accuracy: 0.6671\n",
      "Epoch 82/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6050 - accuracy: 0.6690 - val_loss: 0.6074 - val_accuracy: 0.6672\n",
      "Epoch 83/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6049 - accuracy: 0.6692 - val_loss: 0.6073 - val_accuracy: 0.6672\n",
      "Epoch 84/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6048 - accuracy: 0.6694 - val_loss: 0.6072 - val_accuracy: 0.6674\n",
      "Epoch 85/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6047 - accuracy: 0.6695 - val_loss: 0.6071 - val_accuracy: 0.6675\n",
      "Epoch 86/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6046 - accuracy: 0.6694 - val_loss: 0.6070 - val_accuracy: 0.6676\n",
      "Epoch 87/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6045 - accuracy: 0.6696 - val_loss: 0.6069 - val_accuracy: 0.6677\n",
      "Epoch 88/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.6043 - accuracy: 0.6698 - val_loss: 0.6068 - val_accuracy: 0.6678\n",
      "Epoch 89/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6042 - accuracy: 0.6697 - val_loss: 0.6068 - val_accuracy: 0.6677\n",
      "Epoch 90/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6041 - accuracy: 0.6699 - val_loss: 0.6067 - val_accuracy: 0.6680\n",
      "Epoch 91/5000\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6040 - accuracy: 0.6698 - val_loss: 0.6066 - val_accuracy: 0.6677\n",
      "Epoch 92/5000\n",
      "3950/3953 [============================>.] - ETA: 0s - loss: 0.6039 - accuracy: 0.6701Restoring model weights from the end of the best epoch: 82.\n",
      "3953/3953 [==============================] - 16s 4ms/step - loss: 0.6039 - accuracy: 0.6701 - val_loss: 0.6065 - val_accuracy: 0.6680\n",
      "Epoch 92: early stopping\n",
      "4257/4257 [==============================] - 7s 2ms/step - loss: 0.6074 - accuracy: 0.6672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 21:45:05,350]\u001b[0m Trial 0 finished with value: 0.6074244976043701 and parameters: {'hidden_layer_sizes': 256, 'activation': 'relu', 'hidden_layers': 2, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'SGD', 'loss_function': 'binary_crossentropy', 'batch_size': 64, 'max_iter': 5000}. Best is trial 0 with value: 0.6074244976043701.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2106 - accuracy: 0.6679 - val_loss: 0.2075 - val_accuracy: 0.6719\n",
      "Epoch 2/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2064 - accuracy: 0.6750 - val_loss: 0.2067 - val_accuracy: 0.6740\n",
      "Epoch 3/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2057 - accuracy: 0.6770 - val_loss: 0.2064 - val_accuracy: 0.6748\n",
      "Epoch 4/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2050 - accuracy: 0.6782 - val_loss: 0.2061 - val_accuracy: 0.6744\n",
      "Epoch 5/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2044 - accuracy: 0.6791 - val_loss: 0.2052 - val_accuracy: 0.6771\n",
      "Epoch 6/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2037 - accuracy: 0.6807 - val_loss: 0.2048 - val_accuracy: 0.6780\n",
      "Epoch 7/2000\n",
      "1977/1977 [==============================] - 7s 4ms/step - loss: 0.2032 - accuracy: 0.6817 - val_loss: 0.2043 - val_accuracy: 0.6787\n",
      "Epoch 8/2000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2028 - accuracy: 0.6821 - val_loss: 0.2041 - val_accuracy: 0.6783\n",
      "Epoch 9/2000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2022 - accuracy: 0.6833 - val_loss: 0.2037 - val_accuracy: 0.6795\n",
      "Epoch 10/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2019 - accuracy: 0.6836 - val_loss: 0.2033 - val_accuracy: 0.6797\n",
      "Epoch 11/2000\n",
      "1977/1977 [==============================] - 7s 4ms/step - loss: 0.2016 - accuracy: 0.6848 - val_loss: 0.2034 - val_accuracy: 0.6805\n",
      "Epoch 12/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2013 - accuracy: 0.6855 - val_loss: 0.2033 - val_accuracy: 0.6799\n",
      "Epoch 13/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2009 - accuracy: 0.6858 - val_loss: 0.2030 - val_accuracy: 0.6812\n",
      "Epoch 14/2000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2007 - accuracy: 0.6865 - val_loss: 0.2029 - val_accuracy: 0.6808\n",
      "Epoch 15/2000\n",
      "1977/1977 [==============================] - 7s 4ms/step - loss: 0.2006 - accuracy: 0.6873 - val_loss: 0.2040 - val_accuracy: 0.6800\n",
      "Epoch 16/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2003 - accuracy: 0.6878 - val_loss: 0.2030 - val_accuracy: 0.6810\n",
      "Epoch 17/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2002 - accuracy: 0.6881 - val_loss: 0.2038 - val_accuracy: 0.6786\n",
      "Epoch 18/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.1999 - accuracy: 0.6889 - val_loss: 0.2032 - val_accuracy: 0.6809\n",
      "Epoch 19/2000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.1998 - accuracy: 0.6892 - val_loss: 0.2030 - val_accuracy: 0.6808\n",
      "Epoch 20/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.1996 - accuracy: 0.6894 - val_loss: 0.2040 - val_accuracy: 0.6781\n",
      "Epoch 21/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.1994 - accuracy: 0.6893 - val_loss: 0.2035 - val_accuracy: 0.6809\n",
      "Epoch 22/2000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.1992 - accuracy: 0.6906 - val_loss: 0.2030 - val_accuracy: 0.6807\n",
      "Epoch 23/2000\n",
      "1956/1977 [============================>.] - ETA: 0s - loss: 0.1990 - accuracy: 0.6907Restoring model weights from the end of the best epoch: 13.\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.1990 - accuracy: 0.6907 - val_loss: 0.2031 - val_accuracy: 0.6808\n",
      "Epoch 23: early stopping\n",
      "4257/4257 [==============================] - 6s 1ms/step - loss: 0.2030 - accuracy: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 21:47:38,665]\u001b[0m Trial 1 finished with value: 0.20302513241767883 and parameters: {'hidden_layer_sizes': 128, 'activation': 'tanh', 'hidden_layers': 1, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'Adam', 'loss_function': 'mse', 'batch_size': 128, 'max_iter': 2000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6459 - accuracy: 0.6555 - val_loss: 0.6445 - val_accuracy: 0.6554\n",
      "Epoch 2/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6444 - accuracy: 0.6555 - val_loss: 0.6443 - val_accuracy: 0.6554\n",
      "Epoch 3/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6443 - accuracy: 0.6555 - val_loss: 0.6443 - val_accuracy: 0.6554\n",
      "Epoch 4/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6443 - accuracy: 0.6555 - val_loss: 0.6443 - val_accuracy: 0.6554\n",
      "Epoch 5/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6443 - accuracy: 0.6555 - val_loss: 0.6443 - val_accuracy: 0.6554\n",
      "Epoch 6/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6443 - accuracy: 0.6555 - val_loss: 0.6443 - val_accuracy: 0.6554\n",
      "Epoch 7/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6442 - accuracy: 0.6555 - val_loss: 0.6442 - val_accuracy: 0.6554\n",
      "Epoch 8/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6442 - accuracy: 0.6555 - val_loss: 0.6442 - val_accuracy: 0.6554\n",
      "Epoch 9/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6442 - accuracy: 0.6555 - val_loss: 0.6442 - val_accuracy: 0.6554\n",
      "Epoch 10/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6442 - accuracy: 0.6555 - val_loss: 0.6442 - val_accuracy: 0.6554\n",
      "Epoch 11/10000\n",
      "1955/1977 [============================>.] - ETA: 0s - loss: 0.6442 - accuracy: 0.6554Restoring model weights from the end of the best epoch: 1.\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.6441 - accuracy: 0.6555 - val_loss: 0.6442 - val_accuracy: 0.6554\n",
      "Epoch 11: early stopping\n",
      "4257/4257 [==============================] - 6s 1ms/step - loss: 0.6445 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 21:48:47,843]\u001b[0m Trial 2 finished with value: 0.6445230841636658 and parameters: {'hidden_layer_sizes': 128, 'activation': 'sigmoid', 'hidden_layers': 1, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'SGD', 'loss_function': 'binary_crossentropy', 'batch_size': 128, 'max_iter': 10000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "7906/7906 [==============================] - 17s 2ms/step - loss: 0.6130 - accuracy: 0.6555 - val_loss: 0.6032 - val_accuracy: 0.6554\n",
      "Epoch 2/2000\n",
      "7906/7906 [==============================] - 15s 2ms/step - loss: 0.5999 - accuracy: 0.6555 - val_loss: 0.6052 - val_accuracy: 0.6554\n",
      "Epoch 3/2000\n",
      "7906/7906 [==============================] - 15s 2ms/step - loss: 0.5976 - accuracy: 0.6555 - val_loss: 0.5995 - val_accuracy: 0.6554\n",
      "Epoch 4/2000\n",
      "7906/7906 [==============================] - 15s 2ms/step - loss: 0.5959 - accuracy: 0.6555 - val_loss: 0.5976 - val_accuracy: 0.6554\n",
      "Epoch 5/2000\n",
      "7906/7906 [==============================] - 15s 2ms/step - loss: 0.5942 - accuracy: 0.6555 - val_loss: 0.5962 - val_accuracy: 0.6554\n",
      "Epoch 6/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5927 - accuracy: 0.6555 - val_loss: 0.5949 - val_accuracy: 0.6554\n",
      "Epoch 7/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5914 - accuracy: 0.6555 - val_loss: 0.5940 - val_accuracy: 0.6554\n",
      "Epoch 8/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5904 - accuracy: 0.6555 - val_loss: 0.5935 - val_accuracy: 0.6554\n",
      "Epoch 9/2000\n",
      "7906/7906 [==============================] - 17s 2ms/step - loss: 0.5895 - accuracy: 0.6555 - val_loss: 0.5928 - val_accuracy: 0.6554\n",
      "Epoch 10/2000\n",
      "7906/7906 [==============================] - 17s 2ms/step - loss: 0.5886 - accuracy: 0.6555 - val_loss: 0.5925 - val_accuracy: 0.6554\n",
      "Epoch 11/2000\n",
      "7906/7906 [==============================] - 17s 2ms/step - loss: 0.5878 - accuracy: 0.6555 - val_loss: 0.5923 - val_accuracy: 0.6554\n",
      "Epoch 12/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5872 - accuracy: 0.6555 - val_loss: 0.5922 - val_accuracy: 0.6554\n",
      "Epoch 13/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5866 - accuracy: 0.6555 - val_loss: 0.5923 - val_accuracy: 0.6554\n",
      "Epoch 14/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5861 - accuracy: 0.6555 - val_loss: 0.5923 - val_accuracy: 0.6554\n",
      "Epoch 15/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5856 - accuracy: 0.6555 - val_loss: 0.5911 - val_accuracy: 0.6554\n",
      "Epoch 16/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5850 - accuracy: 0.6555 - val_loss: 0.5912 - val_accuracy: 0.6554\n",
      "Epoch 17/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5847 - accuracy: 0.6555 - val_loss: 0.5911 - val_accuracy: 0.6554\n",
      "Epoch 18/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5842 - accuracy: 0.6555 - val_loss: 0.5906 - val_accuracy: 0.6554\n",
      "Epoch 19/2000\n",
      "7906/7906 [==============================] - 15s 2ms/step - loss: 0.5838 - accuracy: 0.6555 - val_loss: 0.5906 - val_accuracy: 0.6554\n",
      "Epoch 20/2000\n",
      "7906/7906 [==============================] - 15s 2ms/step - loss: 0.5834 - accuracy: 0.6555 - val_loss: 0.5900 - val_accuracy: 0.6554\n",
      "Epoch 21/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5831 - accuracy: 0.6555 - val_loss: 0.5903 - val_accuracy: 0.6554\n",
      "Epoch 22/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5828 - accuracy: 0.6555 - val_loss: 0.5905 - val_accuracy: 0.6554\n",
      "Epoch 23/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5824 - accuracy: 0.6555 - val_loss: 0.5904 - val_accuracy: 0.6554\n",
      "Epoch 24/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5820 - accuracy: 0.6555 - val_loss: 0.5912 - val_accuracy: 0.6554\n",
      "Epoch 25/2000\n",
      "7906/7906 [==============================] - 17s 2ms/step - loss: 0.5817 - accuracy: 0.6555 - val_loss: 0.5904 - val_accuracy: 0.6554\n",
      "Epoch 26/2000\n",
      "7906/7906 [==============================] - 17s 2ms/step - loss: 0.5814 - accuracy: 0.6555 - val_loss: 0.5911 - val_accuracy: 0.6554\n",
      "Epoch 27/2000\n",
      "7906/7906 [==============================] - 17s 2ms/step - loss: 0.5812 - accuracy: 0.6555 - val_loss: 0.5903 - val_accuracy: 0.6554\n",
      "Epoch 28/2000\n",
      "7906/7906 [==============================] - 18s 2ms/step - loss: 0.5807 - accuracy: 0.6555 - val_loss: 0.5911 - val_accuracy: 0.6554\n",
      "Epoch 29/2000\n",
      "7906/7906 [==============================] - 16s 2ms/step - loss: 0.5806 - accuracy: 0.6555 - val_loss: 0.5905 - val_accuracy: 0.6554\n",
      "Epoch 30/2000\n",
      "7878/7906 [============================>.] - ETA: 0s - loss: 0.5804 - accuracy: 0.6554Restoring model weights from the end of the best epoch: 20.\n",
      "7906/7906 [==============================] - 18s 2ms/step - loss: 0.5803 - accuracy: 0.6555 - val_loss: 0.5931 - val_accuracy: 0.6554\n",
      "Epoch 30: early stopping\n",
      "4257/4257 [==============================] - 5s 1ms/step - loss: 0.5900 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 21:56:55,007]\u001b[0m Trial 3 finished with value: 0.5900291800498962 and parameters: {'hidden_layer_sizes': 32, 'activation': 'tanh', 'hidden_layers': 1, 'output_activation': 'softmax', 'alpha': 0.0001, 'optimizer': 'Adam', 'loss_function': 'binary_crossentropy', 'batch_size': 32, 'max_iter': 2000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2313 - accuracy: 0.6446 - val_loss: 0.2296 - val_accuracy: 0.6484\n",
      "Epoch 2/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2298 - accuracy: 0.6483 - val_loss: 0.2284 - val_accuracy: 0.6503\n",
      "Epoch 3/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2286 - accuracy: 0.6498 - val_loss: 0.2273 - val_accuracy: 0.6514\n",
      "Epoch 4/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2275 - accuracy: 0.6507 - val_loss: 0.2263 - val_accuracy: 0.6524\n",
      "Epoch 5/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2265 - accuracy: 0.6517 - val_loss: 0.2254 - val_accuracy: 0.6531\n",
      "Epoch 6/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2256 - accuracy: 0.6525 - val_loss: 0.2246 - val_accuracy: 0.6534\n",
      "Epoch 7/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2248 - accuracy: 0.6531 - val_loss: 0.2239 - val_accuracy: 0.6537\n",
      "Epoch 8/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2241 - accuracy: 0.6535 - val_loss: 0.2232 - val_accuracy: 0.6540\n",
      "Epoch 9/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2235 - accuracy: 0.6539 - val_loss: 0.2227 - val_accuracy: 0.6545\n",
      "Epoch 10/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2229 - accuracy: 0.6541 - val_loss: 0.2221 - val_accuracy: 0.6549\n",
      "Epoch 11/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2223 - accuracy: 0.6546 - val_loss: 0.2216 - val_accuracy: 0.6550\n",
      "Epoch 12/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2218 - accuracy: 0.6548 - val_loss: 0.2212 - val_accuracy: 0.6552\n",
      "Epoch 13/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2213 - accuracy: 0.6550 - val_loss: 0.2207 - val_accuracy: 0.6554\n",
      "Epoch 14/5000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.2209 - accuracy: 0.6552 - val_loss: 0.2203 - val_accuracy: 0.6555\n",
      "Epoch 15/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2205 - accuracy: 0.6554 - val_loss: 0.2199 - val_accuracy: 0.6557\n",
      "Epoch 16/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2201 - accuracy: 0.6556 - val_loss: 0.2196 - val_accuracy: 0.6558\n",
      "Epoch 17/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2197 - accuracy: 0.6559 - val_loss: 0.2193 - val_accuracy: 0.6560\n",
      "Epoch 18/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2194 - accuracy: 0.6560 - val_loss: 0.2190 - val_accuracy: 0.6563\n",
      "Epoch 19/5000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.2191 - accuracy: 0.6560 - val_loss: 0.2187 - val_accuracy: 0.6563\n",
      "Epoch 20/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2188 - accuracy: 0.6562 - val_loss: 0.2184 - val_accuracy: 0.6565\n",
      "Epoch 21/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2185 - accuracy: 0.6564 - val_loss: 0.2181 - val_accuracy: 0.6566\n",
      "Epoch 22/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2182 - accuracy: 0.6567 - val_loss: 0.2179 - val_accuracy: 0.6568\n",
      "Epoch 23/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2179 - accuracy: 0.6571 - val_loss: 0.2176 - val_accuracy: 0.6570\n",
      "Epoch 24/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2177 - accuracy: 0.6573 - val_loss: 0.2174 - val_accuracy: 0.6573\n",
      "Epoch 25/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2174 - accuracy: 0.6576 - val_loss: 0.2172 - val_accuracy: 0.6572\n",
      "Epoch 26/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2172 - accuracy: 0.6577 - val_loss: 0.2170 - val_accuracy: 0.6574\n",
      "Epoch 27/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2170 - accuracy: 0.6580 - val_loss: 0.2168 - val_accuracy: 0.6578\n",
      "Epoch 28/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2168 - accuracy: 0.6581 - val_loss: 0.2166 - val_accuracy: 0.6580\n",
      "Epoch 29/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2166 - accuracy: 0.6584 - val_loss: 0.2164 - val_accuracy: 0.6581\n",
      "Epoch 30/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2164 - accuracy: 0.6586 - val_loss: 0.2163 - val_accuracy: 0.6584\n",
      "Epoch 31/5000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.2162 - accuracy: 0.6589 - val_loss: 0.2161 - val_accuracy: 0.6586\n",
      "Epoch 32/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2160 - accuracy: 0.6591 - val_loss: 0.2159 - val_accuracy: 0.6587\n",
      "Epoch 33/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2159 - accuracy: 0.6592 - val_loss: 0.2158 - val_accuracy: 0.6589\n",
      "Epoch 34/5000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.2157 - accuracy: 0.6594 - val_loss: 0.2156 - val_accuracy: 0.6590\n",
      "Epoch 35/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.2155 - accuracy: 0.6595 - val_loss: 0.2155 - val_accuracy: 0.6593\n",
      "Epoch 36/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2154 - accuracy: 0.6598 - val_loss: 0.2154 - val_accuracy: 0.6594\n",
      "Epoch 37/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2152 - accuracy: 0.6600 - val_loss: 0.2152 - val_accuracy: 0.6597\n",
      "Epoch 38/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2151 - accuracy: 0.6601 - val_loss: 0.2151 - val_accuracy: 0.6598\n",
      "Epoch 39/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2149 - accuracy: 0.6601 - val_loss: 0.2150 - val_accuracy: 0.6600\n",
      "Epoch 40/5000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.2148 - accuracy: 0.6601 - val_loss: 0.2149 - val_accuracy: 0.6601\n",
      "Epoch 41/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2147 - accuracy: 0.6603 - val_loss: 0.2148 - val_accuracy: 0.6600\n",
      "Epoch 42/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.2146 - accuracy: 0.6607 - val_loss: 0.2146 - val_accuracy: 0.6602\n",
      "Epoch 43/5000\n",
      "3953/3953 [==============================] - 14s 3ms/step - loss: 0.2144 - accuracy: 0.6607 - val_loss: 0.2145 - val_accuracy: 0.6606\n",
      "Epoch 44/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2143 - accuracy: 0.6610 - val_loss: 0.2144 - val_accuracy: 0.6608\n",
      "Epoch 45/5000\n",
      "3953/3953 [==============================] - 15s 4ms/step - loss: 0.2142 - accuracy: 0.6611 - val_loss: 0.2143 - val_accuracy: 0.6609\n",
      "Epoch 46/5000\n",
      "3953/3953 [==============================] - 14s 4ms/step - loss: 0.2141 - accuracy: 0.6612 - val_loss: 0.2142 - val_accuracy: 0.6611\n",
      "Epoch 47/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2140 - accuracy: 0.6614 - val_loss: 0.2141 - val_accuracy: 0.6612\n",
      "Epoch 48/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2139 - accuracy: 0.6614 - val_loss: 0.2140 - val_accuracy: 0.6613\n",
      "Epoch 49/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2138 - accuracy: 0.6617 - val_loss: 0.2140 - val_accuracy: 0.6613\n",
      "Epoch 50/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2137 - accuracy: 0.6619 - val_loss: 0.2139 - val_accuracy: 0.6614\n",
      "Epoch 51/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2136 - accuracy: 0.6618 - val_loss: 0.2138 - val_accuracy: 0.6614\n",
      "Epoch 52/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2135 - accuracy: 0.6621 - val_loss: 0.2137 - val_accuracy: 0.6615\n",
      "Epoch 53/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2134 - accuracy: 0.6622 - val_loss: 0.2136 - val_accuracy: 0.6614\n",
      "Epoch 54/5000\n",
      "3953/3953 [==============================] - 13s 3ms/step - loss: 0.2133 - accuracy: 0.6624 - val_loss: 0.2135 - val_accuracy: 0.6616\n",
      "Epoch 55/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2132 - accuracy: 0.6625 - val_loss: 0.2135 - val_accuracy: 0.6616\n",
      "Epoch 56/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2131 - accuracy: 0.6625 - val_loss: 0.2134 - val_accuracy: 0.6616\n",
      "Epoch 57/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2130 - accuracy: 0.6626 - val_loss: 0.2133 - val_accuracy: 0.6617\n",
      "Epoch 58/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2129 - accuracy: 0.6627 - val_loss: 0.2132 - val_accuracy: 0.6617\n",
      "Epoch 59/5000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2129 - accuracy: 0.6628 - val_loss: 0.2132 - val_accuracy: 0.6618\n",
      "Epoch 60/5000\n",
      "3933/3953 [============================>.] - ETA: 0s - loss: 0.2128 - accuracy: 0.6630Restoring model weights from the end of the best epoch: 50.\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.2128 - accuracy: 0.6630 - val_loss: 0.2131 - val_accuracy: 0.6619\n",
      "Epoch 60: early stopping\n",
      "4257/4257 [==============================] - 7s 2ms/step - loss: 0.2139 - accuracy: 0.6614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:08:59,016]\u001b[0m Trial 4 finished with value: 0.21386414766311646 and parameters: {'hidden_layer_sizes': 128, 'activation': 'tanh', 'hidden_layers': 2, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'SGD', 'loss_function': 'mse', 'batch_size': 64, 'max_iter': 5000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 2/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 3/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 4/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 5/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 6/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 7/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 8/10000\n",
      "3953/3953 [==============================] - 10s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 9/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 10/10000\n",
      "3953/3953 [==============================] - 10s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 11/10000\n",
      "3945/3953 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.6555Restoring model weights from the end of the best epoch: 1.\n",
      "3953/3953 [==============================] - 10s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 11: early stopping\n",
      "4257/4257 [==============================] - 7s 2ms/step - loss: 0.3446 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:10:48,626]\u001b[0m Trial 5 finished with value: 0.34456583857536316 and parameters: {'hidden_layer_sizes': 32, 'activation': 'tanh', 'hidden_layers': 2, 'output_activation': 'softmax', 'alpha': 0.01, 'optimizer': 'Adam', 'loss_function': 'mse', 'batch_size': 64, 'max_iter': 10000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7906/7906 [==============================] - 20s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 2/10000\n",
      "7906/7906 [==============================] - 20s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 3/10000\n",
      "7906/7906 [==============================] - 23s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 4/10000\n",
      "7906/7906 [==============================] - 21s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 5/10000\n",
      "7906/7906 [==============================] - 20s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 6/10000\n",
      "7906/7906 [==============================] - 18s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 7/10000\n",
      "7906/7906 [==============================] - 19s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 8/10000\n",
      "7906/7906 [==============================] - 21s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 9/10000\n",
      "7906/7906 [==============================] - 20s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 10/10000\n",
      "7906/7906 [==============================] - 22s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 11/10000\n",
      "7895/7906 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.6555Restoring model weights from the end of the best epoch: 1.\n",
      "7906/7906 [==============================] - 21s 3ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 11: early stopping\n",
      "4257/4257 [==============================] - 7s 2ms/step - loss: 0.3446 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:14:41,691]\u001b[0m Trial 6 finished with value: 0.34456583857536316 and parameters: {'hidden_layer_sizes': 128, 'activation': 'sigmoid', 'hidden_layers': 1, 'output_activation': 'softmax', 'alpha': 0.01, 'optimizer': 'SGD', 'loss_function': 'mse', 'batch_size': 32, 'max_iter': 10000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 2/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 3/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 4/5000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 5/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 6/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 7/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 8/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 9/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 10/5000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 11/5000\n",
      "3930/3953 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.6555Restoring model weights from the end of the best epoch: 1.\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.3445 - accuracy: 0.6555 - val_loss: 0.3446 - val_accuracy: 0.6554\n",
      "Epoch 11: early stopping\n",
      "4257/4257 [==============================] - 6s 1ms/step - loss: 0.3446 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:16:19,896]\u001b[0m Trial 7 finished with value: 0.34456583857536316 and parameters: {'hidden_layer_sizes': 32, 'activation': 'relu', 'hidden_layers': 1, 'output_activation': 'softmax', 'alpha': 0.01, 'optimizer': 'SGD', 'loss_function': 'mse', 'batch_size': 64, 'max_iter': 5000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2314 - accuracy: 0.6539 - val_loss: 0.2302 - val_accuracy: 0.6546\n",
      "Epoch 2/10000\n",
      "1977/1977 [==============================] - 7s 4ms/step - loss: 0.2293 - accuracy: 0.6552 - val_loss: 0.2285 - val_accuracy: 0.6553\n",
      "Epoch 3/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2279 - accuracy: 0.6554 - val_loss: 0.2274 - val_accuracy: 0.6554\n",
      "Epoch 4/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2269 - accuracy: 0.6554 - val_loss: 0.2266 - val_accuracy: 0.6554\n",
      "Epoch 5/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2263 - accuracy: 0.6555 - val_loss: 0.2261 - val_accuracy: 0.6554\n",
      "Epoch 6/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2259 - accuracy: 0.6555 - val_loss: 0.2257 - val_accuracy: 0.6554\n",
      "Epoch 7/10000\n",
      "1977/1977 [==============================] - 8s 4ms/step - loss: 0.2256 - accuracy: 0.6555 - val_loss: 0.2255 - val_accuracy: 0.6554\n",
      "Epoch 8/10000\n",
      "1977/1977 [==============================] - 7s 4ms/step - loss: 0.2254 - accuracy: 0.6555 - val_loss: 0.2253 - val_accuracy: 0.6554\n",
      "Epoch 9/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2252 - accuracy: 0.6555 - val_loss: 0.2252 - val_accuracy: 0.6554\n",
      "Epoch 10/10000\n",
      "1977/1977 [==============================] - 7s 4ms/step - loss: 0.2251 - accuracy: 0.6555 - val_loss: 0.2251 - val_accuracy: 0.6554\n",
      "Epoch 11/10000\n",
      "1977/1977 [==============================] - 7s 4ms/step - loss: 0.2250 - accuracy: 0.6555 - val_loss: 0.2250 - val_accuracy: 0.6554\n",
      "Epoch 12/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2249 - accuracy: 0.6555 - val_loss: 0.2249 - val_accuracy: 0.6554\n",
      "Epoch 13/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2248 - accuracy: 0.6555 - val_loss: 0.2248 - val_accuracy: 0.6554\n",
      "Epoch 14/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2248 - accuracy: 0.6555 - val_loss: 0.2248 - val_accuracy: 0.6554\n",
      "Epoch 15/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2247 - accuracy: 0.6555 - val_loss: 0.2247 - val_accuracy: 0.6554\n",
      "Epoch 16/10000\n",
      "1977/1977 [==============================] - 7s 4ms/step - loss: 0.2246 - accuracy: 0.6555 - val_loss: 0.2247 - val_accuracy: 0.6554\n",
      "Epoch 17/10000\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2246 - accuracy: 0.6555 - val_loss: 0.2246 - val_accuracy: 0.6554\n",
      "Epoch 18/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2245 - accuracy: 0.6555 - val_loss: 0.2246 - val_accuracy: 0.6554\n",
      "Epoch 19/10000\n",
      "1977/1977 [==============================] - 6s 3ms/step - loss: 0.2245 - accuracy: 0.6555 - val_loss: 0.2245 - val_accuracy: 0.6554\n",
      "Epoch 20/10000\n",
      "1968/1977 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.6555Restoring model weights from the end of the best epoch: 10.\n",
      "1977/1977 [==============================] - 7s 3ms/step - loss: 0.2244 - accuracy: 0.6555 - val_loss: 0.2245 - val_accuracy: 0.6554\n",
      "Epoch 20: early stopping\n",
      "4257/4257 [==============================] - 8s 2ms/step - loss: 0.2251 - accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:18:43,721]\u001b[0m Trial 8 finished with value: 0.22506356239318848 and parameters: {'hidden_layer_sizes': 128, 'activation': 'relu', 'hidden_layers': 2, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'SGD', 'loss_function': 'mse', 'batch_size': 128, 'max_iter': 10000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.6820 - accuracy: 0.5752 - val_loss: 0.6513 - val_accuracy: 0.6501\n",
      "Epoch 2/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6496 - accuracy: 0.6523 - val_loss: 0.6478 - val_accuracy: 0.6534\n",
      "Epoch 3/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6470 - accuracy: 0.6537 - val_loss: 0.6456 - val_accuracy: 0.6540\n",
      "Epoch 4/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6450 - accuracy: 0.6542 - val_loss: 0.6437 - val_accuracy: 0.6543\n",
      "Epoch 5/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6432 - accuracy: 0.6546 - val_loss: 0.6421 - val_accuracy: 0.6546\n",
      "Epoch 6/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6416 - accuracy: 0.6547 - val_loss: 0.6406 - val_accuracy: 0.6549\n",
      "Epoch 7/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6401 - accuracy: 0.6549 - val_loss: 0.6392 - val_accuracy: 0.6551\n",
      "Epoch 8/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6388 - accuracy: 0.6549 - val_loss: 0.6380 - val_accuracy: 0.6554\n",
      "Epoch 9/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6376 - accuracy: 0.6550 - val_loss: 0.6369 - val_accuracy: 0.6555\n",
      "Epoch 10/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6365 - accuracy: 0.6552 - val_loss: 0.6358 - val_accuracy: 0.6556\n",
      "Epoch 11/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6354 - accuracy: 0.6554 - val_loss: 0.6348 - val_accuracy: 0.6558\n",
      "Epoch 12/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6345 - accuracy: 0.6555 - val_loss: 0.6339 - val_accuracy: 0.6559\n",
      "Epoch 13/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6335 - accuracy: 0.6556 - val_loss: 0.6330 - val_accuracy: 0.6559\n",
      "Epoch 14/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6326 - accuracy: 0.6558 - val_loss: 0.6322 - val_accuracy: 0.6561\n",
      "Epoch 15/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6318 - accuracy: 0.6559 - val_loss: 0.6314 - val_accuracy: 0.6563\n",
      "Epoch 16/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6310 - accuracy: 0.6561 - val_loss: 0.6307 - val_accuracy: 0.6565\n",
      "Epoch 17/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6302 - accuracy: 0.6565 - val_loss: 0.6299 - val_accuracy: 0.6566\n",
      "Epoch 18/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6295 - accuracy: 0.6567 - val_loss: 0.6292 - val_accuracy: 0.6568\n",
      "Epoch 19/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6288 - accuracy: 0.6568 - val_loss: 0.6286 - val_accuracy: 0.6569\n",
      "Epoch 20/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6281 - accuracy: 0.6571 - val_loss: 0.6279 - val_accuracy: 0.6573\n",
      "Epoch 21/10000\n",
      "3953/3953 [==============================] - 7s 2ms/step - loss: 0.6274 - accuracy: 0.6573 - val_loss: 0.6273 - val_accuracy: 0.6574\n",
      "Epoch 22/10000\n",
      "3953/3953 [==============================] - 7s 2ms/step - loss: 0.6268 - accuracy: 0.6574 - val_loss: 0.6267 - val_accuracy: 0.6576\n",
      "Epoch 23/10000\n",
      "3953/3953 [==============================] - 7s 2ms/step - loss: 0.6262 - accuracy: 0.6577 - val_loss: 0.6261 - val_accuracy: 0.6578\n",
      "Epoch 24/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6256 - accuracy: 0.6580 - val_loss: 0.6256 - val_accuracy: 0.6580\n",
      "Epoch 25/10000\n",
      "3953/3953 [==============================] - 7s 2ms/step - loss: 0.6250 - accuracy: 0.6581 - val_loss: 0.6251 - val_accuracy: 0.6583\n",
      "Epoch 26/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6245 - accuracy: 0.6584 - val_loss: 0.6245 - val_accuracy: 0.6586\n",
      "Epoch 27/10000\n",
      "3953/3953 [==============================] - 7s 2ms/step - loss: 0.6239 - accuracy: 0.6587 - val_loss: 0.6240 - val_accuracy: 0.6586\n",
      "Epoch 28/10000\n",
      "3953/3953 [==============================] - 7s 2ms/step - loss: 0.6234 - accuracy: 0.6589 - val_loss: 0.6236 - val_accuracy: 0.6588\n",
      "Epoch 29/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6229 - accuracy: 0.6591 - val_loss: 0.6231 - val_accuracy: 0.6588\n",
      "Epoch 30/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6224 - accuracy: 0.6592 - val_loss: 0.6226 - val_accuracy: 0.6591\n",
      "Epoch 31/10000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.6220 - accuracy: 0.6594 - val_loss: 0.6222 - val_accuracy: 0.6592\n",
      "Epoch 32/10000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.6215 - accuracy: 0.6596 - val_loss: 0.6218 - val_accuracy: 0.6594\n",
      "Epoch 33/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6211 - accuracy: 0.6597 - val_loss: 0.6214 - val_accuracy: 0.6594\n",
      "Epoch 34/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6206 - accuracy: 0.6599 - val_loss: 0.6210 - val_accuracy: 0.6596\n",
      "Epoch 35/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6202 - accuracy: 0.6600 - val_loss: 0.6206 - val_accuracy: 0.6597\n",
      "Epoch 36/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6198 - accuracy: 0.6603 - val_loss: 0.6202 - val_accuracy: 0.6598\n",
      "Epoch 37/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6194 - accuracy: 0.6605 - val_loss: 0.6199 - val_accuracy: 0.6598\n",
      "Epoch 38/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6190 - accuracy: 0.6605 - val_loss: 0.6195 - val_accuracy: 0.6598\n",
      "Epoch 39/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6187 - accuracy: 0.6609 - val_loss: 0.6192 - val_accuracy: 0.6600\n",
      "Epoch 40/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6183 - accuracy: 0.6611 - val_loss: 0.6189 - val_accuracy: 0.6601\n",
      "Epoch 41/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6180 - accuracy: 0.6613 - val_loss: 0.6185 - val_accuracy: 0.6601\n",
      "Epoch 42/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6176 - accuracy: 0.6613 - val_loss: 0.6182 - val_accuracy: 0.6600\n",
      "Epoch 43/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6173 - accuracy: 0.6616 - val_loss: 0.6179 - val_accuracy: 0.6604\n",
      "Epoch 44/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6170 - accuracy: 0.6618 - val_loss: 0.6177 - val_accuracy: 0.6607\n",
      "Epoch 45/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6167 - accuracy: 0.6620 - val_loss: 0.6174 - val_accuracy: 0.6607\n",
      "Epoch 46/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6164 - accuracy: 0.6620 - val_loss: 0.6171 - val_accuracy: 0.6608\n",
      "Epoch 47/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6161 - accuracy: 0.6623 - val_loss: 0.6168 - val_accuracy: 0.6610\n",
      "Epoch 48/10000\n",
      "3953/3953 [==============================] - 12s 3ms/step - loss: 0.6158 - accuracy: 0.6623 - val_loss: 0.6166 - val_accuracy: 0.6613\n",
      "Epoch 49/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6155 - accuracy: 0.6623 - val_loss: 0.6163 - val_accuracy: 0.6614\n",
      "Epoch 50/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6152 - accuracy: 0.6625 - val_loss: 0.6161 - val_accuracy: 0.6612\n",
      "Epoch 51/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6150 - accuracy: 0.6626 - val_loss: 0.6158 - val_accuracy: 0.6615\n",
      "Epoch 52/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6147 - accuracy: 0.6627 - val_loss: 0.6156 - val_accuracy: 0.6612\n",
      "Epoch 53/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6145 - accuracy: 0.6628 - val_loss: 0.6154 - val_accuracy: 0.6616\n",
      "Epoch 54/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6142 - accuracy: 0.6630 - val_loss: 0.6152 - val_accuracy: 0.6618\n",
      "Epoch 55/10000\n",
      "3953/3953 [==============================] - 10s 3ms/step - loss: 0.6140 - accuracy: 0.6630 - val_loss: 0.6150 - val_accuracy: 0.6621\n",
      "Epoch 56/10000\n",
      "3953/3953 [==============================] - 10s 3ms/step - loss: 0.6138 - accuracy: 0.6633 - val_loss: 0.6147 - val_accuracy: 0.6620\n",
      "Epoch 57/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6135 - accuracy: 0.6634 - val_loss: 0.6145 - val_accuracy: 0.6620\n",
      "Epoch 58/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6133 - accuracy: 0.6636 - val_loss: 0.6144 - val_accuracy: 0.6620\n",
      "Epoch 59/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6131 - accuracy: 0.6637 - val_loss: 0.6142 - val_accuracy: 0.6622\n",
      "Epoch 60/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6129 - accuracy: 0.6637 - val_loss: 0.6140 - val_accuracy: 0.6623\n",
      "Epoch 61/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6127 - accuracy: 0.6639 - val_loss: 0.6138 - val_accuracy: 0.6623\n",
      "Epoch 62/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6125 - accuracy: 0.6641 - val_loss: 0.6136 - val_accuracy: 0.6626\n",
      "Epoch 63/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6123 - accuracy: 0.6643 - val_loss: 0.6134 - val_accuracy: 0.6626\n",
      "Epoch 64/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6121 - accuracy: 0.6643 - val_loss: 0.6133 - val_accuracy: 0.6628\n",
      "Epoch 65/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6119 - accuracy: 0.6645 - val_loss: 0.6131 - val_accuracy: 0.6631\n",
      "Epoch 66/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6117 - accuracy: 0.6648 - val_loss: 0.6129 - val_accuracy: 0.6631\n",
      "Epoch 67/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6116 - accuracy: 0.6650 - val_loss: 0.6128 - val_accuracy: 0.6633\n",
      "Epoch 68/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6114 - accuracy: 0.6648 - val_loss: 0.6126 - val_accuracy: 0.6633\n",
      "Epoch 69/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6112 - accuracy: 0.6650 - val_loss: 0.6125 - val_accuracy: 0.6634\n",
      "Epoch 70/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6110 - accuracy: 0.6650 - val_loss: 0.6123 - val_accuracy: 0.6634\n",
      "Epoch 71/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6109 - accuracy: 0.6650 - val_loss: 0.6122 - val_accuracy: 0.6635\n",
      "Epoch 72/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6107 - accuracy: 0.6651 - val_loss: 0.6120 - val_accuracy: 0.6636\n",
      "Epoch 73/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6106 - accuracy: 0.6653 - val_loss: 0.6119 - val_accuracy: 0.6638\n",
      "Epoch 74/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6104 - accuracy: 0.6655 - val_loss: 0.6118 - val_accuracy: 0.6638\n",
      "Epoch 75/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6103 - accuracy: 0.6656 - val_loss: 0.6116 - val_accuracy: 0.6639\n",
      "Epoch 76/10000\n",
      "3953/3953 [==============================] - 11s 3ms/step - loss: 0.6101 - accuracy: 0.6657 - val_loss: 0.6115 - val_accuracy: 0.6640\n",
      "Epoch 77/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6100 - accuracy: 0.6658 - val_loss: 0.6114 - val_accuracy: 0.6641\n",
      "Epoch 78/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6098 - accuracy: 0.6659 - val_loss: 0.6112 - val_accuracy: 0.6641\n",
      "Epoch 79/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6097 - accuracy: 0.6659 - val_loss: 0.6111 - val_accuracy: 0.6641\n",
      "Epoch 80/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6096 - accuracy: 0.6661 - val_loss: 0.6110 - val_accuracy: 0.6642\n",
      "Epoch 81/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6094 - accuracy: 0.6663 - val_loss: 0.6109 - val_accuracy: 0.6646\n",
      "Epoch 82/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6093 - accuracy: 0.6662 - val_loss: 0.6108 - val_accuracy: 0.6644\n",
      "Epoch 83/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6092 - accuracy: 0.6665 - val_loss: 0.6107 - val_accuracy: 0.6645\n",
      "Epoch 84/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6091 - accuracy: 0.6665 - val_loss: 0.6106 - val_accuracy: 0.6644\n",
      "Epoch 85/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6089 - accuracy: 0.6666 - val_loss: 0.6104 - val_accuracy: 0.6644\n",
      "Epoch 86/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6088 - accuracy: 0.6667 - val_loss: 0.6103 - val_accuracy: 0.6649\n",
      "Epoch 87/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6087 - accuracy: 0.6667 - val_loss: 0.6102 - val_accuracy: 0.6649\n",
      "Epoch 88/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6086 - accuracy: 0.6669 - val_loss: 0.6101 - val_accuracy: 0.6650\n",
      "Epoch 89/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6085 - accuracy: 0.6669 - val_loss: 0.6100 - val_accuracy: 0.6649\n",
      "Epoch 90/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6084 - accuracy: 0.6671 - val_loss: 0.6099 - val_accuracy: 0.6651\n",
      "Epoch 91/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6083 - accuracy: 0.6671 - val_loss: 0.6098 - val_accuracy: 0.6651\n",
      "Epoch 92/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6081 - accuracy: 0.6671 - val_loss: 0.6097 - val_accuracy: 0.6652\n",
      "Epoch 93/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6080 - accuracy: 0.6672 - val_loss: 0.6096 - val_accuracy: 0.6653\n",
      "Epoch 94/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6079 - accuracy: 0.6673 - val_loss: 0.6095 - val_accuracy: 0.6654\n",
      "Epoch 95/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6078 - accuracy: 0.6673 - val_loss: 0.6094 - val_accuracy: 0.6654\n",
      "Epoch 96/10000\n",
      "3953/3953 [==============================] - 10s 3ms/step - loss: 0.6077 - accuracy: 0.6674 - val_loss: 0.6093 - val_accuracy: 0.6654\n",
      "Epoch 97/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6076 - accuracy: 0.6675 - val_loss: 0.6093 - val_accuracy: 0.6654\n",
      "Epoch 98/10000\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6075 - accuracy: 0.6675 - val_loss: 0.6092 - val_accuracy: 0.6655\n",
      "Epoch 99/10000\n",
      "3953/3953 [==============================] - 10s 3ms/step - loss: 0.6075 - accuracy: 0.6676 - val_loss: 0.6091 - val_accuracy: 0.6656\n",
      "Epoch 100/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6074 - accuracy: 0.6676 - val_loss: 0.6090 - val_accuracy: 0.6657\n",
      "Epoch 101/10000\n",
      "3953/3953 [==============================] - 10s 2ms/step - loss: 0.6073 - accuracy: 0.6676 - val_loss: 0.6089 - val_accuracy: 0.6658\n",
      "Epoch 102/10000\n",
      "3953/3953 [==============================] - 9s 2ms/step - loss: 0.6072 - accuracy: 0.6677 - val_loss: 0.6088 - val_accuracy: 0.6657\n",
      "Epoch 103/10000\n",
      "3927/3953 [============================>.] - ETA: 0s - loss: 0.6072 - accuracy: 0.6676Restoring model weights from the end of the best epoch: 93.\n",
      "3953/3953 [==============================] - 8s 2ms/step - loss: 0.6071 - accuracy: 0.6676 - val_loss: 0.6088 - val_accuracy: 0.6659\n",
      "Epoch 103: early stopping\n",
      "4257/4257 [==============================] - 6s 1ms/step - loss: 0.6096 - accuracy: 0.6653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:33:22,221]\u001b[0m Trial 9 finished with value: 0.6096231937408447 and parameters: {'hidden_layer_sizes': 32, 'activation': 'tanh', 'hidden_layers': 1, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'SGD', 'loss_function': 'binary_crossentropy', 'batch_size': 64, 'max_iter': 10000}. Best is trial 1 with value: 0.20302513241767883.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "n_trials = 10\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'hidden_layer_sizes': 128, 'activation': 'tanh', 'hidden_layers': 1, 'output_activation': 'sigmoid', 'alpha': 0.0001, 'optimizer': 'Adam', 'loss_function': 'mse', 'batch_size': 128, 'max_iter': 2000}\n",
      "Best objective value:  0.20302513241767883\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters: ', study.best_params)\n",
    "print('Best objective value: ', study.best_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Saving study**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./optuna_studies/mlp_study.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = './optuna_studies/mlp_study.pkl'\n",
    "\n",
    "joblib.dump(study, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
