{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 23:28:26.457192: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-15 23:28:26.493112: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-15 23:28:26.493932: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-15 23:28:27.314877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from data.data_loader import get_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "train_tensor, validation_tensor, test_tensor = get_data(selected_fold=1, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "training_data = train_tensor.cache().shuffle(961).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_data = validation_tensor.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_data = test_tensor.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg import VGG\n",
    "\n",
    "model = VGG(img_dimension=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3f400be3d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 23:28:29.650448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1825]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-15 23:28:29.650923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1825]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - ETA: 0s - loss: 0.6954 - roc_auc: 0.6582 - binary_accuracy: 0.7047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 23:34:19.301016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [609]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 461s 7s/step - loss: 0.6954 - roc_auc: 0.6582 - binary_accuracy: 0.7047 - val_loss: 0.5182 - val_roc_auc: 0.8616 - val_binary_accuracy: 0.6995 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "66/66 [==============================] - 442s 7s/step - loss: 0.5248 - roc_auc: 0.7544 - binary_accuracy: 0.7266 - val_loss: 0.4841 - val_roc_auc: 0.8817 - val_binary_accuracy: 0.8243 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.5073 - roc_auc: 0.7813 - binary_accuracy: 0.7649 - val_loss: 0.4640 - val_roc_auc: 0.8840 - val_binary_accuracy: 0.8095 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.5113 - roc_auc: 0.7796 - binary_accuracy: 0.7792 - val_loss: 0.4999 - val_roc_auc: 0.8873 - val_binary_accuracy: 0.8522 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.4641 - roc_auc: 0.8229 - binary_accuracy: 0.7918 - val_loss: 0.4212 - val_roc_auc: 0.8910 - val_binary_accuracy: 0.8539 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.4623 - roc_auc: 0.8237 - binary_accuracy: 0.7945 - val_loss: 0.4308 - val_roc_auc: 0.9008 - val_binary_accuracy: 0.8473 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.4568 - roc_auc: 0.8385 - binary_accuracy: 0.8060 - val_loss: 0.3975 - val_roc_auc: 0.9022 - val_binary_accuracy: 0.8555 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "66/66 [==============================] - 442s 7s/step - loss: 0.4702 - roc_auc: 0.8161 - binary_accuracy: 0.7918 - val_loss: 0.4191 - val_roc_auc: 0.9009 - val_binary_accuracy: 0.8407 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.4653 - roc_auc: 0.8238 - binary_accuracy: 0.8082 - val_loss: 0.4585 - val_roc_auc: 0.8998 - val_binary_accuracy: 0.8621 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.4442 - roc_auc: 0.8348 - binary_accuracy: 0.8027 - val_loss: 0.3584 - val_roc_auc: 0.9050 - val_binary_accuracy: 0.8588 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.4634 - roc_auc: 0.8191 - binary_accuracy: 0.7984 - val_loss: 0.3934 - val_roc_auc: 0.9064 - val_binary_accuracy: 0.8522 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "66/66 [==============================] - 441s 7s/step - loss: 0.4489 - roc_auc: 0.8369 - binary_accuracy: 0.8077 - val_loss: 0.4763 - val_roc_auc: 0.9075 - val_binary_accuracy: 0.7980 - lr: 0.0100\n",
      "Epoch 13/1000\n",
      "66/66 [==============================] - 442s 7s/step - loss: 0.4794 - roc_auc: 0.8073 - binary_accuracy: 0.7797 - val_loss: 0.4481 - val_roc_auc: 0.9064 - val_binary_accuracy: 0.8539 - lr: 0.0100\n",
      "Epoch 14/1000\n",
      "66/66 [==============================] - 446s 7s/step - loss: 0.4409 - roc_auc: 0.8391 - binary_accuracy: 0.7989 - val_loss: 0.4456 - val_roc_auc: 0.9104 - val_binary_accuracy: 0.8407 - lr: 0.0100\n",
      "Epoch 15/1000\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.4444 - roc_auc: 0.8448 - binary_accuracy: 0.8142Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "66/66 [==============================] - 463s 7s/step - loss: 0.4444 - roc_auc: 0.8448 - binary_accuracy: 0.8142 - val_loss: 0.4508 - val_roc_auc: 0.9061 - val_binary_accuracy: 0.8374 - lr: 0.0100\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_data,\n",
    "    validation_data,\n",
    "    learning_rate=0.01,\n",
    "    patience=5,\n",
    "    epochs=1000,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('vgg_model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be8e997fbdc1ff99c03ccd8070361faa309a5347a5a70f010cee8e163bdcfe9e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
